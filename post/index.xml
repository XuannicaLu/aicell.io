<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts | AICell Lab</title><link>https://aicell.io/post/</link><atom:link href="https://aicell.io/post/index.xml" rel="self" type="application/rss+xml"/><description>Posts</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Fri, 23 Jun 2023 00:00:00 +0000</lastBuildDate><image><url>https://aicell.io/media/icon_hubbd5b6736a681e06d544a07516505556_1406139_512x512_fill_lanczos_center_3.png</url><title>Posts</title><link>https://aicell.io/post/</link></image><item><title>Hosting Hackathon on Web &amp; Cloud for AI-powered BioImage Analysis</title><link>https://aicell.io/post/web-cloud-hackathon-stockholm-2023/</link><pubDate>Fri, 23 Jun 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/post/web-cloud-hackathon-stockholm-2023/</guid><description>&lt;h1 id="hosting-hackathon-on-web--cloud-for-ai-powered-bioimage-analysis">Hosting Hackathon on Web &amp;amp; Cloud for AI-powered BioImage Analysis&lt;/h1>
&lt;p>&lt;em>Originally Posted by &lt;a href="https://focalplane.biologists.com/author/cfusterbarcelo/" target="_blank" rel="noopener">Caterina Fuster-Barceló&lt;/a>, title: &amp;ldquo;Outcomes of the Hackathon on Web and Cloud Infrastructure for AI-Powered BioImage Analysis&amp;rdquo; on 22 June 2023&lt;/em>&lt;/p>
&lt;p>Recently, our community had the opportunity to partake in a dynamic event that demonstrated the vibrant nature of our field: The &lt;a href="https://ai4life.eurobioimaging.eu/" target="_blank" rel="noopener">AI4Life&lt;/a> Hackathon on Web and Cloud Infrastructure for AI-Powered BioImage Analysis. This event, organized by Wei Ouyang at KTH Sweden, partner of the AI4Life, with generous support from Global BioImaging, took place from June 5th to 9th, 2023, at the distinguished SciLifeLab in Stockholm, Sweden.&lt;/p>
&lt;p>The objective of this hackathon was to bring together thought leaders from various backgrounds to discuss and design advanced web/cloud infrastructure for bioimage analysis, using the latest AI tools. This fusion of technology and biology aimed to drive future advancements in the life sciences and computing arenas.&lt;/p>
&lt;h2 id="from-everywhere-to-the-scilifelab">From everywhere to the SciLifeLab&lt;/h2>
&lt;p>We welcomed a myriad of participants from around the globe, representing prestigious institutions and industrial partners from both the EU and the US. The renowned platforms present at the event, such as the BioImage Model Zoo (BMZ), Fiji, ITK, Apeer, Knime, ImJoy, Piximi, Icy, and deepImageJ, each demonstrated their unique contributions to the evolving field of bioimage analysis.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://focalplane.biologists.com/2023/06/22/outcomes-of-the-hackathon-on-web-and-cloud-infrastructure-for-ai-powered-bioimage-analysis/whatsapp-image-2023-06-20-at-17-15-31-1/" alt="Wei Ouyang’s presentation of Hypha and BioEngine." loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="presentations-and-demos">Presentations and demos!&lt;/h2>
&lt;p>The kick-off of the hackathon featured a series of introductions and presentations. Wei Ouyang, the leader of the newly founded AICell Lab, presented a compelling overview of his team’s work, including the development of &lt;a href="https://github.com/amun-ai/hypha" target="_blank" rel="noopener">Hypha&lt;/a> and &lt;a href="https://aicell.io/project/bioengine" target="_blank" rel="noopener">BioEngine&lt;/a> which serves as a robust platform for running AI models in the cloud and &lt;a href="https://forum.image.sc/t/ai-assisted-bioimage-analysis-with-openai-codex/62045" target="_blank" rel="noopener">a large language model-based tool for code generation in image analysis&lt;/a>.&lt;/p>
&lt;p>Next up, the &lt;a href="https://www.piximi.app/" target="_blank" rel="noopener">Piximi&lt;/a> team impressed the attendees with their demonstration of how AI models can be run in a web browser using JavaScript, showcasing a powerful annotation tool for bioimage analysis. Not to be outdone, the &lt;a href="https://www.apeer.com/app" target="_blank" rel="noopener">APEER&lt;/a> platform revealed its latest feature for training AI models and subsequent local downloads for inference.&lt;/p>
&lt;h2 id="the-talkathon">The “talkathon”&lt;/h2>
&lt;p>Initially, the hackathon resembled a “talkathon”, with participants passionately engaging in dynamic discussions, creating synergy and forming interest groups. These conversations traversed a broad spectrum of topics, ranging from enhancing the usability of client tools, supporting custom pre/postprocessing (like StarDist or Cellpose), and even complex inference modes such as test-time augmentation. The consensus was achieved by proposing an ‘ops’ registry — a GitHub repository that stores dependencies and entry point codes for running custom bioimage analysis operations. In essence, this would create a library of operations that could be linked to each model in the BMZ, with each model potentially having multiple operations.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://focalplane.biologists.com/2023/06/22/outcomes-of-the-hackathon-on-web-and-cloud-infrastructure-for-ai-powered-bioimage-analysis/ima_607550a/" alt="Hackathon participants" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://focalplane.biologists.com/2023/06/22/outcomes-of-the-hackathon-on-web-and-cloud-infrastructure-for-ai-powered-bioimage-analysis/ima_17456e2-1/" alt="Hackathon participants" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="hands-on">Hands-on&lt;/h2>
&lt;p>As the hackathon progressed, it shifted focus towards practical collaboration. Participants dove into hands-on activities, such as linking tools like Piximi and Knime to BioEngine, developing guidelines for assigning task-specific tags, and exploring remote rendering capabilities with &lt;a href="https://www.allencell.org/pathtrace-rendering.html" target="_blank" rel="noopener">AGAVE&lt;/a> and &lt;a href="https://kitware.github.io/itk-vtk-viewer/docs/" target="_blank" rel="noopener">itk-vtk-viewer&lt;/a>, among other tasks.&lt;/p>
&lt;h2 id="conclusions">Conclusions&lt;/h2>
&lt;p>While the hackathon itself has concluded, the collaborations it sparked continue. Participants are building on the progress made during the event, marking the beginning of what we anticipate to be a series of exciting advancements in the field. We firmly believe that this event will catalyze further progress in the bioimaging and AI communities and eagerly&lt;/p></description></item><item><title>New DDLS Fellow: Wei Ouyang</title><link>https://aicell.io/post/ddls-fellow-wei-ouyang/</link><pubDate>Wed, 10 May 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/post/ddls-fellow-wei-ouyang/</guid><description>&lt;h1 id="new-ddls-fellow-wei-ouyang">New DDLS Fellow: Wei Ouyang&lt;/h1>
&lt;p>&lt;em>Originally Posted on &lt;a href="https://www.scilifelab.se/news/new-ddls-fellow-wei-ouyang/" target="_blank" rel="noopener">SciLifeLab website&lt;/a>, on 10th May 2023&lt;/em>&lt;/p>
&lt;p>&lt;strong>During 2023, the SciLifeLab &amp;amp; Wallenberg National Program for Data-Driven Life Science (DDLS) continued the recruitment of new fellows. Get to know our latest fellow, Wei Ouyang (KTH), in our Q&amp;amp;A-style article series. Wei will join the Cell and molecular biology research area.&lt;/strong>&lt;/p>
&lt;p>Wei began his academic journey in engineering sciences in China before moving to Paris to pursue his PhD in 2014. There, he focused on AI and advanced microscopy imaging. In 2019, he joined Emma Lundberg’s group at SciLifeLab &amp;amp; KTH as a postdoctoral researcher for four years. Before joining DDLS, Wei had the opportunity to spend some months at Stanford University as a visiting scholar.&lt;/p>
&lt;p>Passionate about developing AI-based computational methods and open-source platforms to democratize AI in life science, Wei is actively involved in consortiums and community activities that promote open, scalable, accessible, and reproducible data-driven life science.&lt;/p>
&lt;p>He is now thrilled to establish the &lt;a href="https://aicell.io" target="_blank" rel="noopener">AICell Lab&lt;/a> at SciLifeLab, which focuses on building AI-systems for cell and molecular biology. The lab’s ambition is to create a large-scale human cell simulator powered by massive AI models and automated microscopy imaging farms.&lt;/p>
&lt;p>&lt;strong>How do you think your expertise can contribute to the program?&lt;/strong>&lt;/p>
&lt;p>Given the current advancements in AI, particularly the significant progress in generative modelling like chatGPT and Diffusion models, I see enormous potential for applying these foundational models to data-driven life sciences in a fully data-driven manner. Translating the successes from natural language processing and computer vision to life sciences requires a deep understanding of the methods, as well as highly interdisciplinary expertise in AI, data science, and biology, among other areas. It demands not only innovation in data analysis but also in data generation. My experience in robotic systems, AI-powered advanced microscopy, image and multi-omics data analysis, data-driven whole-cell modelling, open-source AI tool development, and online data sharing and AI model serving platforms makes me well-suited to contribute to these efforts.&lt;/p>
&lt;p>In addition to my technical expertise, I strongly believe in the importance of open-source software development and community engagement in scientific research. I have been actively involved in creating and sharing tools that make deep learning more accessible to researchers, as well as promoting open and reproducible scientific tools. My experience in community building and leadership will be invaluable in driving and reforming the data-driven life science program, fostering collaboration, and accelerating progress in this exciting and rapidly evolving field.&lt;/p>
&lt;p>&lt;strong>Shortly describe your research in an easy to understand way.&lt;/strong>&lt;/p>
&lt;p>My research focuses on creating a “black-box” human cell simulator using powerful AI models. This ambitious project involves developing autonomous systems to collect massive amounts of high-quality data for AI training, including building a fully automated imaging farm. By running AI models in real-time, we create a self-driving imaging and cell experimentation system, which allows us to optimize experimental conditions and capture rare cellular events.&lt;/p>
&lt;p>Ultimately, our goal is to develop a human cell simulator that unlocks the potential for in-silico cell experimentation, drug discovery, and fosters a holistic understanding of human cells.&lt;/p>
&lt;p>&lt;strong>How do you think the program and interactions with the other DDLS-Fellows will benefit you?&lt;/strong>&lt;/p>
&lt;p>The DDLS program is a visionary investment in the next generation of life science and offers a fantastic starting package to build a community that pioneers the future of the field. Being a part of this program has given me the incredible opportunity to establish my own research group.&lt;/p>
&lt;p>Interacting with other DDLS-Fellows allows us to help each other, learn, and grow together. The program also serves as a platform for expanding my network of collaborations and learning new skills from experts both within and outside the program. I believe that, in the future, we will see even more coordinated efforts to shape data-driven life sciences through these valuable connections.&lt;/p>
&lt;p>&lt;strong>Name one thing that people generally do not know about you.&lt;/strong>&lt;/p>
&lt;p>Throughout my studies, I developed a fascination for computational philosophy and the view of the universe as a giant computer. The concept of emergent behaviour from the iterative evaluation of simple rules, similar to how cells in biology and large language models in AI function, particularly intrigued me. This has inspired my passion for developing a human cell simulator, as it presents a unique and exciting opportunity to delve into the underlying rules governing cellular behaviour.&lt;/p>
&lt;p>&lt;strong>Where do you see yourself in five years regarding the DDLS aspect?&lt;/strong>&lt;/p>
&lt;p>In five years, I envision myself having established a robust framework for data-driven whole-cell simulation, contributing significantly&lt;/p>
&lt;p>&lt;strong>In one word, describe how you feel about becoming a DDLS-Fellow.&lt;/strong>&lt;/p>
&lt;p>Empowered&lt;/p></description></item><item><title>Wei Ouyang Receives Göran Gustafsson Prize in Applied Physics</title><link>https://aicell.io/post/gustafsson-prize-wei-ouyang/</link><pubDate>Tue, 09 May 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/post/gustafsson-prize-wei-ouyang/</guid><description>&lt;h1 id="wei-ouyang-receives-göran-gustafsson-prize-in-applied-physics">Wei Ouyang Receives Göran Gustafsson Prize in Applied Physics&lt;/h1>
&lt;p>&lt;em>Originally Posted on &lt;a href="https://gustafssonsstiftelser.se/wei-ouyang-teknisk-fysik-kth/" target="_blank" rel="noopener">gustafssonsstiftelser website (in Swedish)&lt;/a>, on 9th May 2023&lt;/em>&lt;/p>
&lt;p>Wei Ouyang receives the Göran Gustafsson prize in Applied Physics at KTH. The prize provides Wei a worth &lt;strong>3 million SEK&lt;/strong>, spread over three years.&lt;/p>
&lt;p>Wei grew up in southern China and received his doctorate in 2018 at the Institut Pasteur, Paris, France. After his PhD, Wei spent four years as a postdoctoral researcher at SciLifeLab and KTH.&lt;/p>
&lt;p>&lt;strong>Wei Ouyang describes his research as follows&lt;/strong>: My work is focused on building artificial intelligence systems for cell and molecular biology. My interdisciplinary group, AICell Lab, focuses on creating data-driven whole-cell models with the ambitious goal of constructing a human cell simulator. To achieve this, Wei and his team are working on innovations in data analysis, modeling and generation with an emphasis on the importance of autonomous systems for the collection of huge amounts of high-quality data suitable for training AI models.&lt;/p>
&lt;p>Wei further says that his group is developing a fully automated imaging system, equipped with multiple microscopes, robotic arms, liquid handling robots and automated incubators. He highlights that AI models run in real-time to augment microscope views with artificial labels and annotations, enabling feedback signals to control cell growth, differentiation, and to adjust microscope settings to optimize phototoxicity and capture rare events in living cells.&lt;/p>
&lt;p>The long-term goal of Wei&amp;rsquo;s research is to create large-scale whole human cell models by combining existing multi-omics datasets with new data generated by the imaging system. He envisions these human cell models as having great potential in cell experimentation in silicon, drug discovery, and contributing to a holistic and systematic understanding of the human cell.&lt;/p>
&lt;p>Outside the laboratory, Wei says he enjoys exploring the Stockholm archipelago and snowboarding in the winter.&lt;/p></description></item><item><title>AI-assisted BioImage Analysis with GPT models</title><link>https://aicell.io/post/openai-codex-for-ai-assisted-bioimage-analysis/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/post/openai-codex-for-ai-assisted-bioimage-analysis/</guid><description>&lt;h1 id="ai-assisted-bioimage-analysis-with-openai-gpt-models">AI-assisted BioImage Analysis with OpenAI GPT models&lt;/h1>
&lt;p>&lt;em>Originally Posted on &lt;a href="https://forum.image.sc/t/ai-assisted-bioimage-analysis-with-openai-codex/" target="_blank" rel="noopener">image.sc&lt;/a>, on 17th Jan 2022&lt;/em>&lt;/p>
&lt;p>Deep learning has already revolutionized the way we do image analysis, now it comes the latest AI models for natural language processing which will change the way we interact with bioimage analysis software.&lt;/p>
&lt;p>Here is an Open AI codex demo showing how one can generate Python code from English for bioimage analysis including cellpose segmentation, feature extraction and plotting!&lt;/p>
&lt;p>Watch the video here:&lt;/p>
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/pkOp_oUybsc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>&lt;/iframe>
&lt;p>This type of code generation technology is ideally suited for users without programming skills, and provides a solution for building simple interface for complex scientific software. It enables us to build next generation software that are powerful, flexible, but with only very simple speech or text prompt interface.&lt;/p>
&lt;p>It can completely change how software tools are delivered to the users. Since the codex model can read developer document and generate code based on the documentation, developers can focus on making reusable library and forget about the GUI part. For each bioimage anlysis task, we can provide a prompt (a chunk of text with hint on how to perform a certain task) and user can then use English or other natural language to send instruction to perform the analysis task. During the code generation, reusable UI components such as jupyter widgets, imjoy plugins or napari can be used to provide rich interaction.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Software UI and Codex|690x365" srcset="
/post/openai-codex-for-ai-assisted-bioimage-analysis/featured_hu5453d1c9f2a85d3494f69ad2deae4fac_64827_1cdc5a0d40bcf9d3a9d87bd3c1650212.webp 400w,
/post/openai-codex-for-ai-assisted-bioimage-analysis/featured_hu5453d1c9f2a85d3494f69ad2deae4fac_64827_f085f0aa00d20b3c9a17ee40f6ed9d2c.webp 760w,
/post/openai-codex-for-ai-assisted-bioimage-analysis/featured_hu5453d1c9f2a85d3494f69ad2deae4fac_64827_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://aicell.io/post/openai-codex-for-ai-assisted-bioimage-analysis/featured_hu5453d1c9f2a85d3494f69ad2deae4fac_64827_1cdc5a0d40bcf9d3a9d87bd3c1650212.webp"
width="760"
height="403"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The key difference compared to conventional software design is that the code are generated on the fly, and it effectively makes the user (without programming skills) a developer and makes the software more generalizable for more applications. In addition, the generated software can be reused and published, for example, one can easily generate napari or ImJoy plugins with codex model.&lt;/p>
&lt;p>However, as of now, the Codex model remains a black box and we do not have an actual way of controlling the code generation process besides the prompt and instructions. As a result, the generated code are not always correct and safe to run on the user&amp;rsquo;s computer (e.g. it might accidentally remove all the data). Therefore, it is safer to run it in a sandbox environment, e.g. in the browser or docker containers.&lt;/p>
&lt;p>On the other hand, ImJoy is ideally suited for working with AI generated code because every ImJoy plugin runs in its own sandbox environment and it is easy enough to contain AI generate code that might go wrong seriously. Within the #ImJoy team, we are currently developing a new interface based on Codex code generation. The new interface will be accessible from a web browser and connected to a cloud infrastructure that allows multi-model serving, data management and serverless app hosting.&lt;/p>
&lt;p>Meanwhile, we are happy to hear your thoughts about this new direction!&lt;/p></description></item></channel></rss>