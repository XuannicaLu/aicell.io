<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>deep learning | AICell Lab</title><link>https://aicell.io/tag/deep-learning/</link><atom:link href="https://aicell.io/tag/deep-learning/index.xml" rel="self" type="application/rss+xml"/><description>deep learning</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate><image><url>https://aicell.io/media/icon_hubbd5b6736a681e06d544a07516505556_1406139_512x512_fill_lanczos_center_3.png</url><title>deep learning</title><link>https://aicell.io/tag/deep-learning/</link></image><item><title>AI4Life - AI Models for BioImaging</title><link>https://aicell.io/project/ai4life/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/ai4life/</guid><description>&lt;p>AI4LIFE is a Horizon Europe-funded project that brings together the computational and life science communities. Its goal is to empower life science researchers to harness the full potential of Artificial Intelligence (AI) and Machine Learning (ML) methods for bioimage analysis – and in particular microscopy image analysis, by providing services, and developing standards aimed at both developers and users. With a consortium of ten partners, AI4LIFE promises to create harmonized and interoperable AI tools &amp;amp; methods via Open calls and public challenges and bring these developments to researchers via strategic outreach and advanced training. The services provided and solutions developed within the AI4LIFE framework are crucial to solving today’s microscopy image analysis problems and will contribute to boosting the pace of biological and medical insights and discovery in the coming years.&lt;/p>
&lt;p>For more information about the project, check it out at the &lt;a href="https://ai4life.eurobioimaging.eu/" target="_blank" rel="noopener">AI4Life website&lt;/a>.&lt;/p>
&lt;p>The AICell Lab at KTH is a leading partner in the AI4Life consortium. We focus on supporting the user services and cloud computing infrastructure via BioImage Model Zoo (&lt;a href="https://bioimage.io" target="_blank" rel="noopener">https://bioimage.io&lt;/a>). The model zoo is a community-driven, fully open resource where standardized pre-trained models can be shared, explored, tested, and downloaded for further adaptation or direct deployment in multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath, StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep). To enable everyone to contribute and consume the Zoo resources, we provide a model standard to enable cross-compatibility, a rich list of example models and practical use-cases, developer tools, documentation, and the accompanying infrastructure for model upload, download and testing. Our contribution aims to lay the groundwork to make deep learning methods for microscopy imaging findable, accessible, interoperable, and reusable (FAIR) across software tools and platforms.&lt;/p>
&lt;p>For more details about the model zoo, see our publication &lt;a href="https://www.biorxiv.org/content/10.1101/2022.06.07.495102v1" target="_blank" rel="noopener">here&lt;/a>.&lt;/p></description></item><item><title>Human Cell Simulator</title><link>https://aicell.io/project/human-cell-simulator/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/human-cell-simulator/</guid><description>&lt;p>Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of building a human cell simulator through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.&lt;/p></description></item><item><title>ImJoy - Web Data Analysis</title><link>https://aicell.io/project/imjoy/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/imjoy/</guid><description>&lt;p>Deep learning (DL) methods achieve breakthrough performances in analyzing biomedical data across countless tasks, including medical diagnostics, DNA sequence analysis, augmented microscopy and drug design. Combined with increasing data repositories in genomics, imaging and other fields, such successes underlay a growing demand to adapt DL methods to new datasets and questions1. However, the dissemination of DL approaches faces considerable hurdles. Most published DL studies2,3,4,5 require users to retrain models on their own data to obtain the best performance and/or avoid erroneous results. Although trained models are frequently available through web applications or ImageJ plugins, retraining is typically only possible via scripts or command lines, rather than graphical user interfaces (GUIs). In addition, the complexities of setting up the required hardware and software environments often constitute forbidding obstacles6. Furthermore, the large datasets and computational resources typical of current DL successes pose challenges to traditional desktop-oriented software that tightly couple GUI and computation. Cloud services can partly alleviate these difficulties, but raise privacy and confidentiality issues that can be prohibitive for medical data7. Meanwhile, deploying scientific software to mobile platforms can make them accessible to billions of people8, enabling large-scale biomedical research and citizen science. These opportunities and challenges call for new computational frameworks.&lt;/p>
&lt;p>For more information, read our publication on &lt;a href="https://www.nature.com/articles/s41592-019-0627-0" target="_blank" rel="noopener">Nature Methods&lt;/a>.&lt;/p>
&lt;h2 id="live-demos">Live Demos&lt;/h2>
&lt;p>This website contains ImJoy integration, you can find some example applications for image visualization below:&lt;/p>
&lt;div id="menu-container">&lt;/div>
&lt;h3 id="itkvtk-viewer">ITK/VTK Viewer&lt;/h3>
&lt;p>To visualize an image with ITK/VTK viewer, click &lt;button onclick="api.showDialog({src: 'https://kitware.github.io/itk-vtk-viewer/app/', data: {image: 'https://images.proteinatlas.org/115/672_E2_1_blue_red_green.jpg'}})">here&lt;/button>&lt;/p>
&lt;h3 id="vizarr-example">Vizarr Example&lt;/h3>
&lt;p>Vizarr be embedded in the page directly:&lt;/p>
&lt;div id="vizarr-embeded-1">&lt;/div>
&lt;br>
You can also view the image in a dialog by clicking &lt;button onclick="imjoy.vizarr('https://uk1s3.embassy.ebi.ac.uk/idr/zarr/v0.1/4495402.zarr')">here&lt;/button></description></item><item><title>Reef - Automated Imaging Farm</title><link>https://aicell.io/project/reef-imaging-farm/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/reef-imaging-farm/</guid><description>&lt;p>The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.&lt;/p></description></item><item><title>Self-driving Microscope</title><link>https://aicell.io/project/self-driving-microscope/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/self-driving-microscope/</guid><description>&lt;p>The aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the Jaldén group at KTH. The Jaldén group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the Jaldén group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.&lt;/p></description></item></channel></rss>