<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>microscopy | AICell Lab</title><link>https://aicell.io/tag/microscopy/</link><atom:link href="https://aicell.io/tag/microscopy/index.xml" rel="self" type="application/rss+xml"/><description>microscopy</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Sun, 01 Jan 2023 00:00:00 +0000</lastBuildDate><image><url>https://aicell.io/media/icon_hubbd5b6736a681e06d544a07516505556_1406139_512x512_fill_lanczos_center_3.png</url><title>microscopy</title><link>https://aicell.io/tag/microscopy/</link></image><item><title>Codex Chat Notebook</title><link>https://aicell.io/project/codex-chat-notebook/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/codex-chat-notebook/</guid><description>&lt;p>Deep learning has already revolutionized the way we do image analysis, now it comes the latest AI models for natural language processing which will change the way we interact with bioimage analysis software.&lt;/p>
&lt;p>Here is an Open AI codex demo showing how one can generate Python code from English for bioimage analysis including cellpose segmentation, feature extraction and plotting!&lt;/p>
&lt;p>Watch the video here:&lt;/p>
&lt;iframe width="100%" height="400px" src="https://www.youtube.com/embed/pkOp_oUybsc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen>&lt;/iframe>
&lt;p>This type of code generation technology is ideally suited for users without programming skills, and provides a solution for building simple interface for complex scientific software. It enables us to build next generation software that are powerful, flexible, but with only very simple speech or text prompt interface.&lt;/p>
&lt;p>It can completely change how software tools are delivered to the users. Since the codex model can read developer document and generate code based on the documentation, developers can focus on making reusable library and forget about the GUI part. For each bioimage anlysis task, we can provide a prompt (a chunk of text with hint on how to perform a certain task) and user can then use English or other natural language to send instruction to perform the analysis task. During the code generation, reusable UI components such as jupyter widgets, &lt;a href="https://aicell.io/project/imjoy">ImJoy&lt;/a> plugins or napari can be used to provide rich interaction.&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="./Software-UI-and-Codex.png" alt="Software UI and Codex|690x365" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>The key difference compared to conventional software design is that the code are generated on the fly, and it effectively makes the user (without programming skills) a developer and makes the software more generalizable for more applications. In addition, the generated software can be reused and published, for example, one can easily generate napari or &lt;a href="https://aicell.io/project/imjoy">ImJoy&lt;/a> plugins with codex model.&lt;/p>
&lt;p>However, as of now, the Codex model remains a black box and we do not have an actual way of controlling the code generation process besides the prompt and instructions. As a result, the generated code are not always correct and safe to run on the user&amp;rsquo;s computer (e.g. it might accidentally remove all the data). Therefore, it is safer to run it in a sandbox environment, e.g. in the browser or docker containers.&lt;/p>
&lt;p>On the other hand, &lt;a href="https://aicell.io/project/imjoy">ImJoy&lt;/a> is ideally suited for working with AI generated code because every ImJoy plugin runs in its own sandbox environment and it is easy enough to contain AI generate code that might go wrong seriously. Within the #ImJoy team, we are currently developing a new interface based on Codex code generation. The new interface will be accessible from a web browser and connected to a cloud infrastructure that allows multi-model serving, data management and serverless app hosting.&lt;/p>
&lt;p>In the AICell Lab, we developed the Codex Chat Notebook which aims to use OpenAI Codex to generate python code for image analysis and beyond. The project is currented hosted at: &lt;a href="https://github.com/oeway/codex-chat-notebook" target="_blank" rel="noopener">https://github.com/oeway/codex-chat-notebook&lt;/a>.&lt;/p>
&lt;p>If you have an OpenAI api token (get it from &lt;a href="https://openai.com/blog/openai-codex/" target="_blank" rel="noopener">here&lt;/a>), you can already try it out with our Jupyter notebook running in the browser: &lt;a href="https://jupyter.imjoy.io/lab/index.html" target="_blank" rel="noopener">https://jupyter.imjoy.io/lab/index.html&lt;/a>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="screenshot" srcset="
/project/codex-chat-notebook/codex-chat-notebook-screenshot_hub0334c4252eef004bbc4a0f9f491e904_162881_63baee12699df7108dd323796e5b066a.webp 400w,
/project/codex-chat-notebook/codex-chat-notebook-screenshot_hub0334c4252eef004bbc4a0f9f491e904_162881_5fed63b73b0b5f13f3f48ff1edc84d04.webp 760w,
/project/codex-chat-notebook/codex-chat-notebook-screenshot_hub0334c4252eef004bbc4a0f9f491e904_162881_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://aicell.io/project/codex-chat-notebook/codex-chat-notebook-screenshot_hub0334c4252eef004bbc4a0f9f491e904_162881_63baee12699df7108dd323796e5b066a.webp"
width="760"
height="532"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p></description></item><item><title>Reef - Automated Imaging Farm</title><link>https://aicell.io/project/reef-imaging-farm/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/reef-imaging-farm/</guid><description>&lt;p>The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.&lt;/p></description></item><item><title>Self-driving Microscope</title><link>https://aicell.io/project/self-driving-microscope/</link><pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate><guid>https://aicell.io/project/self-driving-microscope/</guid><description>&lt;p>The aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the Jaldén group at KTH. The Jaldén group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the Jaldén group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.&lt;/p></description></item></channel></rss>