[{"authors":null,"categories":null,"content":" 🔥 We are recruiting Ph.D students and postdocs, check it out! The AICell Lab is a newly formed research group at Science for Life Laboratory and KTH Royal Institute at Technology. The group is led by Wei Ouyang and funded by the Data-Driven Life Science program. The aim of the lab is to build AI systems for data-driven cell and molecular biology.\nRead more about the AICell Lab…\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ea94ad9394f8902e5ea230f6a54da5b5","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"🔥 We are recruiting Ph.D students and postdocs, check it out! The AICell Lab is a newly formed research group at Science for Life Laboratory and KTH Royal Institute at Technology.","tags":null,"title":"AI for Cell Biology Laboratory","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1c899dfb626d109eb5250a094bb04a8d","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"","tags":null,"title":"We Are Hiring!","type":"authors"},{"authors":null,"categories":null,"content":"Wei OUYANG is an assistant professor at the applied physics department, KTH Royal Institute of Technology (Stockholm, Sweden). He is one of the Data-Driven Life Science fellow and currently leading a research group focusing on AI and data-driven method development for bioimage analysis and whole-cell modeling.\nDr. Ouyang obtained his PhD in computational image analysis at Institut Pasteur, Paris where he mainly focuses on applying deep learning for super-resolution microscopy. During this period, he developed a deep learning method called ANNA-PALM which massively accelerates super-resolution localization microscopy by 100x. He spent 4 years at Emma Lundberg’s group as a postdoctoral researcher. To address the challenges in the dissemination of AI tools, he developed an open-source computational platform, ImJoy, which makes deep learning tools easier to build and more accessible to the user. He is actively involved in consortiums and community activities for promoting more open, scalable, accessible and reproducible scientific tools. Among them, he is leading the development of the BioImage Model Zoo for sharing AI models in bioimage analysis.\nDr. Ouyang is mainly interested in AI augmented microscopy imaging and data-driven whole-cell modeling.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1ac1287be249f4356037b3f6a33188a9","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Wei OUYANG is an assistant professor at the applied physics department, KTH Royal Institute of Technology (Stockholm, Sweden). He is one of the Data-Driven Life Science fellow and currently leading a research group focusing on AI and data-driven method development for bioimage analysis and whole-cell modeling.","tags":null,"title":"Wei Ouyang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://aicell.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Research Engineer for AI-driven Web and Cloud Software Development\nApplication Open Soon (Deadline: TBD)\nJob description The AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and Science for Life Laboratory is a new research group funded by the Data-driven Life Science Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now opening a position for a research engineer who will work on software development for AI-powered data management and lab automation.\nThe research engineer will be responsible for building web-based user interfaces, computational backends, and managing container-based computing clusters. You will have the opportunity to work on exciting projects such as the AI-powered automated imaging farm, which involves robotic and imaging hardware control, experiment planning, and real-time AI-powered data analysis. You will collaborate with teams from Stanford University and develop AI platforms based on our existing open source projects such as ImJoy, ImageJ.JS and BioEngine. Additionally, they will work with international consortia such as the EU-supported research infrastructure project AI4Life for building the Bioimage Model Zoo and creating cloud-based AI computing infrastructure for deploying AI to research institutions and used by the masses.\nResponsibilities include:\nDeveloping software and web-based user interfaces for AI-powered data management and lab automation\nBuilding computational backends for AI systems and managing container-based computing clusters\nCollaborating with interdisciplinary teams on the Reef - Automated Imaging Farm.\nImplementing AI and machine learning methods for bioimage analysis\nMaintaining and improving the BioImage Model Zoo platform and related cloud-based infrastructure\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A graduate degree or an advanced level (higher education) in computer science, engineering, or a related field\nKnowledge and experience of software development\nExcellent knowledge in English since this is needed in your daily work.\nPreferred qualifications Strong programming skills in Python, JavaScript, and other relevant languages\nExperience with web development frameworks and libraries (e.g., React or Vue)\nFamiliarity with cloud services, containerization technologies (e.g., Docker, Kubernetes) and distributed computing systems\nBackground in AI, machine learning, or data science, preferably with a focus on bioimage analysis\nExperience with robotics, image analysis, hardware control, and lab automation\nStrong problem-solving skills and ability to work in a fast-paced, interdisciplinary research environment\nExcellent communication and collaboration skills\nCollaborative abilities, and scientific communication\nGreat emphasis will be placed on personal competency. We are looking for someone who is reliable, collaborative, and communicative. You need to be able to work independently, actively contribute to problem solving, and to help move projects forward. It is commendable if you are well organized and thorough. As an employee at KTH, awareness of diversity and equal opportunity issues, with specific focus on gender equality, is required.\nTrade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe application must include:\nCV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.\nCopy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.\nPersonal letter about your previous experience, personal competencies, career goals, why you want to conduct research, your interests and how they relate to your previous studies and future goals. Max two pages long.\nYour complete application must be received by KTH no later than the last day of application, midnight\nCET/CEST (Central European Time/Central European Summer Time).\nAbout the employment The employment is valid for a limited time according to the agreement - for up to 12 months, with access according to agreement. There may …","date":1681948800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1681948800,"objectID":"ad84dcc397a30e375636fe5164913a30","permalink":"https://aicell.io/recruiting/engineer-1-ai4life/","publishdate":"2023-04-20T00:00:00Z","relpermalink":"/recruiting/engineer-1-ai4life/","section":"recruiting","summary":"Title: Research Engineer for AI-driven Web and Cloud Software Development\nApplication Open Soon (Deadline: TBD)\nJob description The AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and Science for Life Laboratory is a new research group funded by the Data-driven Life Science Fellows program.","tags":["engineer","open"],"title":"Research Engineer for AI-driven Web and Cloud Software Development","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Doctoral Student in Cell Biology and Computational Microscopy Imaging\nApplication Deadline: 27.April.2023\nKTH Royal Institute of Technology in Stockholm has grown to become one of Europe’s leading technical and engineering universities, as well as a key centre of intellectual talent and innovation. We are Sweden’s largest technical research and learning institution and home to students, researchers and faculty from around the world. Our research and education covers a wide area including natural sciences and all branches of engineering, as well as architecture, industrial management, urban planning, history and philosophy.\nProject description Third-cycle subject: Biological Physics\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and Science for Life Laboratory is a new research group funded by the Data-driven Life Science Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now opening a position for a doctoral student in biological physics with a focus on robotics and AI-powered microscopy imaging.\nYou will actively contribute to the design and implementation of an automated microscopy imaging farm, encompassing hardware integration, optics optimization, robotics engineering, and automation systems development. Additionally, you will be involved in developing cutting-edge AI models for data analysis, designing real-time feedback control systems for active data acquisition, and working on data-driven whole-cell modeling initiatives to advance our research objectives.\nSupervision: Professor Hjalmar Brismar and Assistant Professor Wei Ouyang are proposed to supervise the doctoral student. Decisions are made on admission.\nWhat we offer The possibility to study in a dynamic and international research environment in collaboration with industries and prominent universities from all over the world. Read more\nA workplace with many employee benefits and monthly salary according to KTH’s Doctoral student salary agreement.\nA postgraduate education at an institution that is active and supportive in matters pertaining to working conditions, gender equality and diversity as well as study environment.\nWork and study in Stockholm, close to nature and the water.\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nAdmission requirements To be admitted to postgraduate education (Chapter 7, 39 § Swedish Higher Education Ordinance), the applicant must have basic eligibility in accordance with either of the following:\npassed a second cycle degree (for example a master’s degree), or\ncompleted course requirements of at least 240 higher education credits, of which at least 60 second-cycle higher education credits, or\nacquired, in some other way within or outside the country, substantially equivalent knowledge\nType in the special eligibility the applicant also shall meet.\nIn addition to the above, there is also a mandatory requirement for English equivalent to English B/6, read more here\nSelection In order to succeed as a doctoral student at KTH you need to be goal oriented and persevering in your work. During the selection process, candidates will be assessed upon their ability to:\nAbility to work independently and effectively manage time. Collaborative mindset and experience working in interdisciplinary teams. Ability to cross disciplines and exhibit a passion for AI, robotics, lab automation and data-driven life science. Previous training in electronics design, optics, mechanical engineering, computer vision, robotics and machine learning. Proficiency in programming languages, including Python, C/C++, JavaScript, and Bash. Previous experience in working with AI, machine learning, deep learning, microscopy image analysis, desktop and web software design, robotic and control systems. Strong demonstrated hands-on skills, with a proven ability to effectively handle experimental setups, instrumentation, and troubleshooting in a research environment. Target degree: Doctoral degree Information regarding admission and employment Only those admitted to postgraduate education may be employed as a doctoral student. The total length of employment may not be longer than what corresponds to full-time doctoral education in four years ’ time. An employed doctoral student can, to a limited extent (maximum 20%), perform certain tasks within their role, e.g. training and administration. A new position as a doctoral student is for a maximum of one year, and then the employment may be renewed for a maximum of two years at a time.\nUnion representatives You will find contact information for union representatives on KTH’s website.\nDoctoral section (Students’ union on KTH Royal Institute of Technology)\nYou will find contact information for doctoral section on the section’s website.\nApplication Apply for the position and admission through KTH’s recruitment …","date":1679961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679961600,"objectID":"abf45e00b7fb25a8a28689e9218fbf4b","permalink":"https://aicell.io/recruiting/phd-1-robotics-microscopy/","publishdate":"2023-03-28T00:00:00Z","relpermalink":"/recruiting/phd-1-robotics-microscopy/","section":"recruiting","summary":"Title: Doctoral Student in Cell Biology and Computational Microscopy Imaging\nApplication Deadline: 27.April.2023\nKTH Royal Institute of Technology in Stockholm has grown to become one of Europe’s leading technical and engineering universities, as well as a key centre of intellectual talent and innovation.","tags":["AI","open"],"title":"Doctoral Student in Robotics and AI for Automated Microscopy Imaging","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Postdoc in Robotics and AI-powered Microscopy Imaging\nApplication Deadline: 28.April.2023\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now seeking a postdoctoral researcher to develop AI-powered automated microscopy imaging systems.\nThe aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.\nThe candidate is expected to develop an integrated system with microscopes, fluidic control, robotic arms, as well as the control software. The project is a collaboration with our collaborator in the WASP program and built on top of our prior work (e.g. squid, ImJoy) from us or our collaborators at Stanford University.\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.\nThe ability to express yourself in English.\nPreferred qualifications You are passionate, curious and knowledgeable on robotic control Strong background in electronics, optics, mechanical engineering, computer vision and AI Proficient in programming languages such as Python and C/C++, Javascript, Bash Prior experience in microscopy imaging, fluidics systems, digital image analysis and software development is a plus Knowledge inCollaborative abilities, and scientific communication Awareness of diversity and equal opportunity issues, with a specific focus on gender equality Trade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe application must include:\nCV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.\nCopy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.\nBrief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.\nYour complete application must be received by KTH no later than the last day of application, midnight\nCET/CEST (Central European Time/Central European Summer Time).\nAbout the employment The position offered is for, at the most, two years. There may be possibilities to prolong employment.\nA position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.\nOther information Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given part of our values.\nFor information about processing of personal data in the recruitment process please read here.\n","date":1679270400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679270400,"objectID":"6630f595ec911f4c4651764b42161128","permalink":"https://aicell.io/recruiting/postdoc-1-ddls-robotics/","publishdate":"2023-03-20T00:00:00Z","relpermalink":"/recruiting/postdoc-1-ddls-robotics/","section":"recruiting","summary":"Title: Postdoc in Robotics and AI-powered Microscopy Imaging\nApplication Deadline: 28.April.2023\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research.","tags":["AI","Robotics","open"],"title":"Postdoc in Robotics and AI-powered Microscopy Imaging","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Doctoral Student in Cell Biology and Computational Microscopy Imaging\nApplication Closed (Deadline: 20.Feb.2023)\nKTH Royal Institute of Technology in Stockholm has grown to become one of Europe’s leading technical and engineering universities, as well as a key centre of intellectual talent and innovation. We are Sweden’s largest technical research and learning institution and home to students, researchers and faculty from around the world. Our research and education covers a wide area including natural sciences and all branches of engineering, as well as architecture, industrial management, urban planning, history and philosophy.\nProject description Third-cycle subject: Biological Physics\nThe Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now opening a position for a doctoral student in biological physics with a focus on cell biology, automation and AI-augmented microscopy imaging.\nWhole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of modeling the human cell through recent advances in artificial intelligence and multi-omics data generation. To enable large-scale AI and data-driven whole cell modeling, we are currently building a smart microscopy imaging farm to ramp up the production rate of image data. The imaging farm consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated brightfield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. For the whole-cell modeling project, we aim to build an AI-powered automated imaging system to actively detect, monitor and track the live human cells under drug and genetic perturbations. We would like to develop AI models which read changes in cell morphology and fluorescence markers, to generate control signals for driving the microscope, capture rare events and create balanced dataset for modeling.\nYou will be responsible for actively and effectively designing and implementing wet lab experiments in the imaging farm, including cell culture, sample preparation and microscopy imaging. Importantly, you will also actively work with other researchers in the group to develop and adapt protocols for the automated imaging farm and AI models. Besides wet lab skills, you will elaborate on your computational skills, e.g., by writing Python scripts to control the imaging farm, train AI models and develop automated data analysis workflows. In later stages of the project you will also design and conduct additional, custom validation experiments, which may involve different molecular biology techniques.\nSupervision: Professor Hjalmar Brismar and Assistant Professor Wei Ouyang are proposed to supervise the doctoral student. Decisions are made on admission.\nWhat we offer The possibility to study in a dynamic and international research environment in collaboration with industries and prominent universities from all over the world. Read more\nA workplace with many employee benefits and monthly salary according to KTH’s Doctoral student salary agreement.\nA postgraduate education at an institution that is active and supportive in matters pertaining to working conditions, gender equality and diversity as well as study environment.\nWork and study in Stockholm, close to nature and the water.\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nAdmission requirements To be admitted to postgraduate education (Chapter 7, 39 § Swedish Higher Education Ordinance), the applicant must have basic eligibility in accordance with either of the following:\npassed a second cycle degree (for example a master’s degree), or\ncompleted course requirements of at least 240 higher education …","date":1673568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673568e3,"objectID":"5bb60504abe9e1b60e5af19fe4e67434","permalink":"https://aicell.io/recruiting/phd-1-wasp-ddls-biology/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/recruiting/phd-1-wasp-ddls-biology/","section":"recruiting","summary":"Title: Doctoral Student in Cell Biology and Computational Microscopy Imaging\nApplication Closed (Deadline: 20.Feb.2023)\nKTH Royal Institute of Technology in Stockholm has grown to become one of Europe’s leading technical and engineering universities, as well as a key centre of intellectual talent and innovation.","tags":["AI","closed"],"title":"Doctoral Student in Cell Biology and Computational Microscopy Imaging","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Postdoc in AI-powered Automated Microscopy Imaging Systems\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now seeking a postdoctoral researcher to develop AI-powered automated microscopy imaging systems.\nThe aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.\nThe candidate is expected to develop an integrated system with microscopes, fluidic control, robotic arms, as well as the control software. The project is a collaboration with our collaborator in the WASP program and built on top of our prior work (e.g. squid, ImJoy) from us or our collaborators at Stanford University.\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.\nThe ability to express yourself in English.\nPreferred qualifications You are passionate, curious and knowledgeable on developing automated systems\nStrong background in electronics, optics and mechanical engineering\nProficient in programming languages such as Python and C/C++, Javascript, Bash\nPrior experience in building microscopes, fluidics and robotics systems\nPrior experience in building AI models, MLops and tools\nKnowledge in cell biology\nKnowledge in digital image analysis and computer vision\nKnowledge in web technologies (e.g. network communication, browser standards, containerization and kubernetes)\nKnowledge in software design, web services and distributed computing systems\nCollaborative abilities, and scientific communication Awareness of diversity and equal opportunity issues, with a specific focus on gender equality\nGreat emphasis will be placed on personal competency\nTrade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe application must include:\nCV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.\nCopy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.\nBrief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.\nYour complete application must be received by KTH no later than the last day of application, midnight\nCET/CEST (Central European Time/Central European Summer Time).\nAbout the employment The position offered is for, at the most, two years. There may be possibilities to prolong employment.\nA position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a …","date":1673568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673568e3,"objectID":"82766d083858744afdd40e9ff0693e03","permalink":"https://aicell.io/recruiting/postdoc-1-ddls-enginering/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/recruiting/postdoc-1-ddls-enginering/","section":"recruiting","summary":"Title: Postdoc in AI-powered Automated Microscopy Imaging Systems\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research.","tags":["AI","closed"],"title":"Postdoc in AI-powered Automated Microscopy Imaging Systems","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Postdoc in AI-powered Whole-cell Modeling\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now seeking two postdoctoral researchers to build AI systems for spatial multi-omics data analysis and whole-cell modeling.\nWhole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of modeling the human cell through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.\nThe candidates are expected to 1) develop machine learning models and tools for smart microscopy and image analysis 2) integrate multi-omics dataset 3) perform generative modeling and 4) create large-scale differentiable models to do spatial cell simulations. The project will be carried out on top of existing work and collaborate closely with PhDs and postdocs in the group.\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.\nThe ability to express yourself in spoken and written English.\nPreferred qualifications You are passionate and knowledgeable on developing and applying machine learning models to life science applications\nProficient in programming languages such as Python, understanding cloud and web computing technologies is a plus\nTraining in cell and molecular biology\nWet lab experience in cell and molecular biology\nPrior experience in bioimage analysis, genomics sequence analysis, protein folding and metabolic network analysis\nPrior experience in cell modeling and simulation\nPrior experience in fluorescence microscopy imaging\nPrior experience in building deep learning models and tools, microscopy control, software design, web services and distributed computing systems\nKnowledge in popular neural networks architectures, natural language processing models, generative models, AlphaFold\nCollaborative abilities\nAwareness of diversity and equal opportunity issues, with a specific focus on gender equality\nGreat emphasis will be placed on personal competency\nTrade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe application must include:\nCV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.\nCopy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.\nBrief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.\nYour complete application must be received by …","date":1673568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673568e3,"objectID":"1ca53d1c7fc8aa584e1e5b17e9dd6bb5","permalink":"https://aicell.io/recruiting/postdoc-2-ddls-ai/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/recruiting/postdoc-2-ddls-ai/","section":"recruiting","summary":"Title: Postdoc in AI-powered Whole-cell Modeling\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research.","tags":["AI","closed"],"title":"Postdoc in AI-powered Whole-cell Modeling","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Postdoc in Cell Biology and Computational Microscopy Imaging\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now looking for highly motivated candidates to fill a 2-year postdoc position under the WASP-DDLS collaboration.\nThe aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the Jaldén group at KTH. The Jaldén group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the Jaldén group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.\nYou will be responsible for actively and effectively designing, implementing, and optimizing wet lab experiments for the self-driving microscope, including cell culture, sample preparation and microscopy imaging. Importantly, you will also actively work with other researchers in the group to develop and optimize protocols for the automated imaging system and AI models. Besides wet lab skills, you will get the opportunity to elaborate on your computational skills, e.g., by writing Python scripts to control the imaging farm, train AI models and develop automated data analysis workflows. In later stages of the project you will also design and conduct additional, custom validation experiments, which may involve different molecular biology techniques.\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.\nThe ability to express yourself in English.\nPreferred qualifications During the selection process, candidates will be assessed upon their ability to: independently pursue his or her work,\ncollaborate with others,\nsupervise junior people in the lab (e.g., internship and undergraduate students)\nto conceptualize and write publications and scientific reports,\nclearly present scientific concepts and data,\nwork comfortable in an interdisciplinary team,\nhave a professional approach,\nanalyse and work with complex issues,\nhave a solid understanding in cell and molecular biology,\ndemonstrate prior experience with cell culture, molecular biology, high throughput microscopy imaging and other wet lab skills, preferably experience with automated liquid handlers or similar instruments,\ndemonstrate prior experience with developing, establishing, optimizing, and trouble-shootingwet lab protocols,\ncross disciplines, and demonstrate a passion for lab automation, AI and other computational skills,\ndemonstrate prior experience in programming languages such as Python and R.\nPrior experience in data analysis workflow development and machine learning is beneficial.\nGreat emphasis will be placed on personal competency\nTrade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe …","date":1673568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673568e3,"objectID":"5b88ad951b937682132e894715fd04f8","permalink":"https://aicell.io/recruiting/postdoc-1-wasp-ddls-biology/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/recruiting/postdoc-1-wasp-ddls-biology/","section":"recruiting","summary":"Title: Postdoc in Cell Biology and Computational Microscopy Imaging\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research.","tags":["AI","closed"],"title":"Postdoc in Cell Biology and Computational Microscopy Imaging","type":"recruiting"},{"authors":["Wei Ouyang"],"categories":["recruitment"],"content":"Title: Postdoc in Scalable AI Systems for BioImage Analysis\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research. The combination of the highly interdisciplinary expertise and research projects at the department is unique in Sweden and also at an international level. This expertise ranges across cell biology, biochemistry, biophysics and theory. Recently, the SciLifeLab and Wallenberg National Program started the Data-Driven Life Science (DDLS) program in order to accelerate life science research through innovations in AI and data science.\nThe AICell Lab (https://aicell.io) in the department of Applied Physics at KTH and SciLifeLab is a new research group funded by the DDLS Fellows program. The group, led by Wei Ouyang, focuses on building AI systems for data-driven cell and molecular biology. To expand the team, we are now seeking a highly motivated postdoctoral researcher to work on the AI4Life project. AI4Life is a Horizon Europe-funded project that brings together the computational and life science communities. Its goal is to empower life science researchers to harness the full potential of AI for bioimage analysis – and in particular microscopy image analysis, by providing services, and developing standards aimed at both developers and users.\nThe postdoc will work with other AI4Life consortium partners to build scalable AI tools and computing infrastructure for bioimage analysis. There are two aims in the project: 1) Creating web services and computing platforms for sharing AI models, making them more accessible and usable; 2) Building scalable bioimage analysis methods and tools for powering next-generation augmented microscopy. This includes creating tools for collaborative and interactive annotation, model training, real-time inference and generating feedback signal for microscope control.\nThe candidates are expected to collaborate with other AI4Life partners and develop scalable AI methods, tools and platforms on top of our prior work such as the BioImage Model Zoo and ImJoy.\nWhat we offer A position at a leading technical university that generates knowledge and skills for a sustainable future.\nEngaged and ambitious colleagues along with a creative, international and dynamic working environment\nWorks in Stockholm, in close proximity to nature\nCollaboration opportunities with leading research institutions and universities in Europe and the US\nLearning and thriving in a young and ambitious research group\nHelp to relocate and be settled in Sweden and at KTH.\nRead more about what it is like to work at KTH\nQualifications Requirements A doctoral degree or an equivalent foreign degree, This eligibility requirement must be met no later than the time the employment decision is made.\nThe ability to express yourself in English.\nPreferred qualifications You are passionate, curious and knowledgeable on developing web services and tools\nProficient in programming languages such as Python and Javascript, Bash\nProficient in web technologies (e.g. network communication, browser standards, containerization and kubernetes)\nPrior experience in building AI models, MLops and tools\nKnowledge in digital image analysis and computer vision\nKnowledge in software design, web services and distributed computing systems\nCollaborative abilities, and scientific communication Awareness of diversity and equal opportunity issues, with a specific focus on gender equality\nGreat emphasis will be placed on personal competency\nTrade union representatives You will find contact information to trade union representatives at KTH.se\nApplication Log into KTH’s recruitment system in order to apply to this position. You are responsible to ensure that your application is complete according to the instructions in the ad.\nThe application must include:\nCV including relevant professional experience, knowledge and representative publications. Please also provide your Github/Gitlab/Bitbucket etc. handle if possible.\nCopy of diplomas and grades from your previous university studies. Translations into English or Swedish if the original documents have not been issued in any of these languages.\nBrief account of why you want to conduct research, your career goal and how they relate to your previous studies and future goals. Max two pages long.\nYour complete application must be received by KTH no later than the last day of application, midnight\nCET/CEST (Central European Time/Central European Summer Time).\nAbout the employment The position offered is for, at the most, two years. There may be possibilities to prolong employment.\nA position as a postdoctoral fellow is a time-limited qualified appointment focusing mainly on research, intended as a first career step after a dissertation.\nOther information Striving towards gender equality, diversity and equal conditions is both a question of quality for KTH and a given …","date":1673568e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673568e3,"objectID":"92e3d8a52eafa3016ddd1e8d608f4834","permalink":"https://aicell.io/recruiting/postdoc-1-ai4life/","publishdate":"2023-01-13T00:00:00Z","relpermalink":"/recruiting/postdoc-1-ai4life/","section":"recruiting","summary":"Title: Postdoc in Scalable AI Systems for BioImage Analysis\nApplication Closed (Deadline: 22.Feb.2023)\nJob description The Science for Life Laboratory (SciLifeLab) is a national center for molecular biosciences with focus on health and environmental research.","tags":["AI","closed"],"title":"Postdoc in Scalable AI Systems for BioImage Analysis","type":"recruiting"},{"authors":null,"categories":null,"content":"The AICell Lab is an interdisciplinary group which focuses on building AI systems for cell and molecular biology.\nWe would like to take the grand challenge of modeling the human cell and building human cell simulators using powerful AI models. It is an ambitious goal that requires profound innovations in not only data analysis and modeling, but also in data generation. We believe it is crucial for us to build autonomous systems to acquire massive amounts of high quality data that are suitable to train AI models. To this front, we would like to build a fully automated imaging farm which consists of multiple microscopes, robotic arms, liquid handling robots and automatic incubators. Importantly, we run AI models in real-time to augment the microscopy views, generating artificial labels and annotations. It also allows generating feedback signals to or example, control the cell growth, differentiation, and drive the microscope to change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.\nOverall, the long-term goal of the group is to create large-scale whole human cell models trained on existing multi-omics datasets and new data generated by the imaging farm. We envision the human cell models have a great potential in in-silico cell experimentation, drug discovery and contributing to a holistic and systematic understanding of the human cell.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"8576ec274c98b3831668a172fa632d80","permalink":"https://aicell.io/about/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/about/","section":"","summary":"The AICell Lab is a research group led by Wei Ouyang, focuses on building AI systems for cell and molecular biology.","tags":["AI"],"title":"About the AICell Lab","type":"page"},{"authors":null,"categories":null,"content":"AI4LIFE is a Horizon Europe-funded project that brings together the computational and life science communities. Its goal is to empower life science researchers to harness the full potential of Artificial Intelligence (AI) and Machine Learning (ML) methods for bioimage analysis – and in particular microscopy image analysis, by providing services, and developing standards aimed at both developers and users. With a consortium of ten partners, AI4LIFE promises to create harmonized and interoperable AI tools \u0026amp; methods via Open calls and public challenges and bring these developments to researchers via strategic outreach and advanced training. The services provided and solutions developed within the AI4LIFE framework are crucial to solving today’s microscopy image analysis problems and will contribute to boosting the pace of biological and medical insights and discovery in the coming years.\nFor more information about the project, check it out at the AI4Life website.\nThe AICell Lab at KTH is a leading partner in the AI4Life consortium. We focus on supporting the user services and cloud computing infrastructure via BioImage Model Zoo (https://bioimage.io). The model zoo is a community-driven, fully open resource where standardized pre-trained models can be shared, explored, tested, and downloaded for further adaptation or direct deployment in multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath, StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep). To enable everyone to contribute and consume the Zoo resources, we provide a model standard to enable cross-compatibility, a rich list of example models and practical use-cases, developer tools, documentation, and the accompanying infrastructure for model upload, download and testing. Our contribution aims to lay the groundwork to make deep learning methods for microscopy imaging findable, accessible, interoperable, and reusable (FAIR) across software tools and platforms.\nFor more details about the model zoo, see our publication here.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"29b949854508303fde29b0a418077b75","permalink":"https://aicell.io/project/ai4life/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/ai4life/","section":"project","summary":"Creating the AI research infrastructure to support life scientists in the adoption of machine learning solutions in biomedical imaging.","tags":["deep learning","AI","models","FAIR","model zoo"],"title":"AI4Life - AI Models for BioImaging","type":"project"},{"authors":null,"categories":null,"content":"The increasingly amount of data generated in life science poses challenges in managing and analysis. The conventional approach for storing and processing scientific data locally on workstations or laptops is failing to met modern needs in applications such as AI-powered image analysis. We would like to tackle the challenge by introducing the BioEngine platform, which is a computational platform consists of containerized services for scalable data management and AI model serving. It is a web platform built on top of the Hypha with an emphasis on serving models for bioimage analysis.\nIn this project, we aim to develop web services for providing flexible image data management solutions and also model serving in the cloud (private or public). The BioEngine is being used to support the test run feature in the BioImage Model Zoo website (also see the AI4Life project). We aim to provide deployment toolkit for users to setup their own server, either in an institutional Kubernetes cluster or a workstation. Under the AI4Life project, we aim to provide a standard for managing and sharing image data together with the BioImage Archive.\nTo learn more technial details about the BioEngine, please see the tutorial slides here.\nHere, you can also try the BioEngine in an example Jupyter notebook here:\nClick to try BioEngine in Jupyter Lite ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"c3886dc92201009e9a952cbe6e29b9a3","permalink":"https://aicell.io/project/bioengine/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/bioengine/","section":"project","summary":"Web framework for image data management and AI model serving","tags":["deep learning","AI","models","FAIR","model zoo","web"],"title":"BioEngine - AI- \u0026 Web-powered Image Analysis","type":"project"},{"authors":null,"categories":null,"content":"Deep learning has already revolutionized the way we do image analysis, now it comes the latest AI models for natural language processing which will change the way we interact with bioimage analysis software.\nHere is an Open AI codex demo showing how one can generate Python code from English for bioimage analysis including cellpose segmentation, feature extraction and plotting!\nWatch the video here:\nThis type of code generation technology is ideally suited for users without programming skills, and provides a solution for building simple interface for complex scientific software. It enables us to build next generation software that are powerful, flexible, but with only very simple speech or text prompt interface.\nIt can completely change how software tools are delivered to the users. Since the codex model can read developer document and generate code based on the documentation, developers can focus on making reusable library and forget about the GUI part. For each bioimage anlysis task, we can provide a prompt (a chunk of text with hint on how to perform a certain task) and user can then use English or other natural language to send instruction to perform the analysis task. During the code generation, reusable UI components such as jupyter widgets, ImJoy plugins or napari can be used to provide rich interaction.\nThe key difference compared to conventional software design is that the code are generated on the fly, and it effectively makes the user (without programming skills) a developer and makes the software more generalizable for more applications. In addition, the generated software can be reused and published, for example, one can easily generate napari or ImJoy plugins with codex model.\nHowever, as of now, the Codex model remains a black box and we do not have an actual way of controlling the code generation process besides the prompt and instructions. As a result, the generated code are not always correct and safe to run on the user’s computer (e.g. it might accidentally remove all the data). Therefore, it is safer to run it in a sandbox environment, e.g. in the browser or docker containers.\nOn the other hand, ImJoy is ideally suited for working with AI generated code because every ImJoy plugin runs in its own sandbox environment and it is easy enough to contain AI generate code that might go wrong seriously. Within the #ImJoy team, we are currently developing a new interface based on Codex code generation. The new interface will be accessible from a web browser and connected to a cloud infrastructure that allows multi-model serving, data management and serverless app hosting.\nIn the AICell Lab, we developed the Codex Chat Notebook which aims to use OpenAI Codex to generate python code for image analysis and beyond. The project is currented hosted at: https://github.com/oeway/codex-chat-notebook.\nIf you have an OpenAI api token (get it from here), you can already try it out with our Jupyter notebook running in the browser: https://jupyter.imjoy.io/lab/index.html ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"de84935dc40c6e3822e055ceaffeccd5","permalink":"https://aicell.io/project/codex-chat-notebook/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/codex-chat-notebook/","section":"project","summary":"AI-assisted BioImage Analysis with OpenAI CODEX","tags":["deep learning","AI","software","microscopy","bioimaging"],"title":"Codex Chat Notebook","type":"project"},{"authors":null,"categories":null,"content":"Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of building a human cell simulator through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"3fbb3863a4cdff902fe8e942dc51aaa1","permalink":"https://aicell.io/project/human-cell-simulator/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/human-cell-simulator/","section":"project","summary":"Building AI-powered data-driven human whole-cell models","tags":["whole-cell modeling","deep learning","AI","computational biology","simulation","generative modeling"],"title":"Human Cell Simulator","type":"project"},{"authors":null,"categories":null,"content":"Deep learning (DL) methods achieve breakthrough performances in analyzing biomedical data across countless tasks, including medical diagnostics, DNA sequence analysis, augmented microscopy and drug design. Combined with increasing data repositories in genomics, imaging and other fields, such successes underlay a growing demand to adapt DL methods to new datasets and questions1. However, the dissemination of DL approaches faces considerable hurdles. Most published DL studies2,3,4,5 require users to retrain models on their own data to obtain the best performance and/or avoid erroneous results. Although trained models are frequently available through web applications or ImageJ plugins, retraining is typically only possible via scripts or command lines, rather than graphical user interfaces (GUIs). In addition, the complexities of setting up the required hardware and software environments often constitute forbidding obstacles6. Furthermore, the large datasets and computational resources typical of current DL successes pose challenges to traditional desktop-oriented software that tightly couple GUI and computation. Cloud services can partly alleviate these difficulties, but raise privacy and confidentiality issues that can be prohibitive for medical data7. Meanwhile, deploying scientific software to mobile platforms can make them accessible to billions of people8, enabling large-scale biomedical research and citizen science. These opportunities and challenges call for new computational frameworks.\nFor more information, read our publication on Nature Methods.\nLive Demos This website contains ImJoy integration, you can find some example applications for image visualization below:\nKaibu Run Kaibu\nITK/VTK Viewer To visualize an image with ITK/VTK viewer, click here\nVizarr Example Vizarr be embedded in the page directly:\nYou can also view the image in a dialog by clicking here ","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"e30216927b8db55fcce4fc9258591e31","permalink":"https://aicell.io/project/imjoy/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/imjoy/","section":"project","summary":"A computational platform for supercharging scalability and interactivity","tags":["deep learning","AI","web image analysis","web browser","webassembly"],"title":"ImJoy - Web Data Analysis","type":"project"},{"authors":null,"categories":null,"content":"The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.\nHere is a sketch for our cell lab with the imaging farm:\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"b393419260308f5a295bad8d6d547fd0","permalink":"https://aicell.io/project/reef-imaging-farm/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/reef-imaging-farm/","section":"project","summary":"Building AI-powered automated imaging farm for massive image data generation","tags":["deep learning","AI","microscopy","bioimaging","augmented microscopy","robotics","lab automation"],"title":"Reef - Automated Imaging Farm","type":"project"},{"authors":null,"categories":null,"content":"The aim of the project is to develop an AI-powered self-driving microscopy system for studying cellular response under genetic and environmental stressors. The project will also be supported by the WASP-DDLS collaboration, and closely collaborate with the Jaldén group at KTH. The Jaldén group has rich experience in computer vision and automatic control systems. The work will also be supported by the Lundberg group under the Human Protein Atlas, which is a unique world-leading effort to map all the human proteins in cells, tissues, and organs in the human body. By joining the force with the Jaldén group and Lundberg group, we would like to develop an AI-powered imaging system to continuously monitor, actively acquire and track human cells under different cellular and environmental stressors. The data will be used to train large-scale AI models to study cellular responses and make predictions for cell fate.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"32a4dc09e74a59906d60b72545f7ba39","permalink":"https://aicell.io/project/self-driving-microscope/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/self-driving-microscope/","section":"project","summary":"Building an AI-powered self-driving microscopy system for studying cellular response","tags":["deep learning","AI","microscopy","bioimaging","augmented microscopy","robotics","lab automation"],"title":"Self-driving Microscope","type":"project"},{"authors":["Wei Ouyang","Richard W Bowman","Haoran Wang","Kaspar E Bumke","Joel T Collins","Ola Spjuth","Jordi Carreras-Puigvert","Benedict Diederich"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"1fa0cd5d35301893aa9866653b413805","permalink":"https://aicell.io/publication/ouyang-2022-open/","publishdate":"2023-01-15T23:42:15.215275Z","relpermalink":"/publication/ouyang-2022-open/","section":"publication","summary":"","tags":[],"title":"An Open-Source Modular Framework for Automated Pipetting and Imaging Applications","type":"publication"},{"authors":["Trang Le","Casper F Winsnes","Ulrika Axelsson","Hao Xu","Jayasankar Mohanakrishnan Kaimal","Diana Mahdessian","Shubin Dai","Ilya S Makarov","Vladislav Ostankovich","Yang Xu"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"b960050c3ff961eaf0707c0f4440f366","permalink":"https://aicell.io/publication/le-2022-analysis/","publishdate":"2023-01-15T23:42:15.851391Z","relpermalink":"/publication/le-2022-analysis/","section":"publication","summary":"","tags":[],"title":"Analysis of the human protein atlas weakly supervised single-cell classification competition","type":"publication"},{"authors":["Wei Ouyang","Fynn Beuttenmueller","Estibaliz Gómez-de-Mariscal","Constantin Pape","Tom Burke","Carlos Garcia-López-de-Haro","Craig Russell","Lucı́a Moya-Sans","Cristina de-la-Torre-Gutiérrez","Deborah Schmidt"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"9d46faf3922a481b1c58ebb4b6b19435","permalink":"https://aicell.io/publication/ouyang-2022-bioimage/","publishdate":"2023-01-15T23:42:15.70073Z","relpermalink":"/publication/ouyang-2022-bioimage/","section":"publication","summary":"","tags":[],"title":"BioImage Model Zoo: A Community-Driven Resource for Accessible Deep Learning in BioImage Analysis","type":"publication"},{"authors":["Arthur Imbert","Wei Ouyang","Adham Safieddine","Emeline Coleno","Christophe Zimmer","Edouard Bertrand","Thomas Walter","Florian Mueller"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ace415f0785196b567324772555d6f9e","permalink":"https://aicell.io/publication/imbert-2022-fish/","publishdate":"2023-01-15T23:42:15.533744Z","relpermalink":"/publication/imbert-2022-fish/","section":"publication","summary":"","tags":[],"title":"FISH-quant v2: a scalable and modular tool for smFISH image analysis","type":"publication"},{"authors":["Wei Ouyang","Jiachuan Bai","Manish Kumar Singh","Christophe Leterrier","Paul Barthelemy","Samuel FH Barnett","Teresa Klein","Markus Sauer","Pakorn Kanchanawong","Nicolas Bourg"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"2aef7662649d0880990ccc8819b98835","permalink":"https://aicell.io/publication/ouyang-2022-shareloc/","publishdate":"2023-01-15T23:42:16.164704Z","relpermalink":"/publication/ouyang-2022-shareloc/","section":"publication","summary":"","tags":[],"title":"ShareLoc-an open platform for sharing localization microscopy data","type":"publication"},{"authors":["Jayasankar Mohanakrishnan Kaimal","Marianna Tampere","Trang H Le","Ulrika Axelsson","Hao Xu","Hanna Axelsson","Anna Backstrom","Francesco Marabita","Elisabeth Moussaud-Lamodiere","Duncan Njenda"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"b5d4bc5c4bd74d1f43f93714ed705d15","permalink":"https://aicell.io/publication/kaimal-2022-subcellular/","publishdate":"2023-01-15T23:42:15.998042Z","relpermalink":"/publication/kaimal-2022-subcellular/","section":"publication","summary":"","tags":[],"title":"Subcellular mapping of the protein landscape of SARS-CoV-2 infected cells for target-centric drug repurposing","type":"publication"},{"authors":["Matthew R King","Andrew Z Lin","Kiersten M Ruff","Mina Farag","Wei Ouyang","Michael D Vahey","Emma Lundberg","Rohit V Pappu"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"a45bc65019334a279fd4f113e312532b","permalink":"https://aicell.io/publication/king-2022-uncovering/","publishdate":"2023-01-15T23:42:16.315261Z","relpermalink":"/publication/king-2022-uncovering/","section":"publication","summary":"","tags":[],"title":"Uncovering molecular grammars of intrinsically disordered regions that organize nucleolar fibrillar centers","type":"publication"},{"authors":[],"categories":[],"content":"ImJoy: Supercharging Interactivity and Scalability for BioImage Analysis Wei Ouyang\nKTH | SciLifeLab, Stockholm\nChallenges in AI for bioimaging Usability: User friendly GUI Flexibility: Flexible for different data types Interactivity: Respond to GUI on laptop/mobile Scalability: Remote storage and compute resources Privacy: Edge computing Progressive Web App Rich and interactive UI libraries Computation in the browser (+cloud) Offline support ImJoy https://imjoy.io Data science tools in the browser\n----- # Key concepts * Sandboxed plugins connected via Remote Procedure calls * Workflow composition via asynchronous programming * Open Integration with existing software/website Calling Python from JS with RPC Python (cloud) ⇔ Javascript (local) ----- 👐Open Integration with Web Apps Customize annotation workflow with Kaibu\n// load the web app via its URL viewer = await api.createWindow({src: \u0026#34;https://kaibu.org/#/app\u0026#34;}) // call api functions directly via RPC // add an image layer await viewer.view_image(\u0026#34;https://images.proteinatlas.org/61448/1319_C10_2_blue_red_green.jpg\u0026#34;) // add an annotation layer await viewer.add_shapes([], {name:\u0026#34;annotation\u0026#34;}) Run\n🔥Demo: ImJoy + ImageJ =\u0026gt; ImageJ.JS 🔥Demo: Visualization with Vizarr Made by Trevor Manz et. al.\n🚀A rapid growing list of plugins ImageJ.JS Run File Manager Run Vizarr for visualizing zarr images Run ITK/VTK Viewer for 3D visualizing Run ImJoy Slides ImJoy Chart Editor Works with Jupyter/Binder and Colab Advanced AI models in one click! 🤔How it works 🔥Try it yourself! https://bioimage.io\nBioEngine – AI model and application serving Fetch models from bioimage.io Provide web API for model training and inference Support test run models and ImJoy applications Suitable for deploying AI workflows for institutions, facilities or labs Running models in JupyterLite via the BioEngine\nAI-assisted Bioimage Analysis A taste of the future! Powered by OpenAI GPT-3 and Codex\n🔥Codex live demos! Disclaimer! All the demo applications have not yet been approved for launch Please don’t record the demos Seminar at SciLifeLab A sneak peek into the future of AI-assisted life science\nTomorrow (November 23rd), 10:00 - 11:00 CET https://www.scilifelab.se/event/scilifelab-ai-seminar-series-wei-ouyang/ Conclusions ImJoy is built for scalability and interactivity ImJoy plugins are sandbox services connected via RPC BioImage Model Zoo for model sharing BioEninge for AI model serving The future of bioimage anlysis Acknowledgements Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg\nBioImage.IO is powered by the 🧠 and ❤️ of:\ndeepImageJ Team EBI Bioimage Archive Team Fiji/ImageJ Team ilastik Team ImJoy Team ZeroCostDL4Mic Team … Follow us on twitter @bioimageio\nAcknowledgements We thank OpenAI for providing beta testing access to GPT-3 and Codex\nThe demos during this talk has not been approved by OpenAI\n🙏Thank You! 🙏Thank You! const PythonPluginCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;PythonPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;native-python\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;flags\u0026#34;: [], \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [], \u0026#34;dependencies\u0026#34;: [] } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;python\u0026#34;\u0026gt; from imjoy import api class ImJoyPlugin(): def setup(self): api.showMessage(\u0026#39;Python plugin initialized\u0026#39;) def add(self, a, b): return a + b api.export(ImJoyPlugin()) \u0026lt;/script\u0026gt; ` const JSPluginCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;JSPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;window\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [], \u0026#34;dependencies\u0026#34;: [], \u0026#34;defaults\u0026#34;: {\u0026#34;w\u0026#34;: 20, \u0026#34;h\u0026#34;: 10} } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;javascript\u0026#34;\u0026gt; window.callPython = async function(){ const pythonPlugin = await api.getPlugin(\u0026#39;PythonPlugin\u0026#39;) const result = await pythonPlugin.add(10, 99) document.getElementById(\u0026#34;result\u0026#34;).innerHTML = \u0026#34;10 + 99 =\u0026#34; + result } class ImJoyPlugin { async setup() { api.log(\u0026#39;initialized\u0026#39;) } async run(ctx) { } } api.export(new ImJoyPlugin()) \u0026lt;/script\u0026gt; \u0026lt;window lang=\u0026#34;html\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button class=\u0026#34;button\u0026#34; onclick=\u0026#34;callPython()\u0026#34;\u0026gt; Calculate in Python\u0026lt;/button\u0026gt; \u0026lt;h3 id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/window\u0026gt; \u0026lt;style lang=\u0026#34;css\u0026#34;\u0026gt; \u0026lt;/style\u0026gt; ` window.ZarrPythonCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;ZarrPythonPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;native-python\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;flags\u0026#34;: [], \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [\u0026#34;zarr\u0026#34;, \u0026#34;fsspec\u0026#34;], \u0026#34;dependencies\u0026#34;: [] } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;python\u0026#34;\u0026gt; import zarr from imjoy_rpc import api from imjoy_rpc import register_default_codecs from fsspec.implementations.http import …","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612483200,"objectID":"18f800b55b15ac08a8ea3d27298bcf1f","permalink":"https://aicell.io/slides/imjoy/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/slides/imjoy/","section":"slides","summary":"ImJoy","tags":[],"title":"Slides","type":"slides"},{"authors":["Yue Qin","Edward L Huttlin","Casper F Winsnes","Maya L Gosztyla","Ludivine Wacheul","Marcus R Kelly","Steven M Blue","Fan Zheng","Michael Chen","Leah V Schaffer"," others"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ab242eb12325e50c3f34338d392fbd7b","permalink":"https://aicell.io/publication/qin-2021-multi/","publishdate":"2023-01-15T23:42:15.364803Z","relpermalink":"/publication/qin-2021-multi/","section":"publication","summary":"","tags":[],"title":"A multi-scale map of cell structure fusing protein images and interactions","type":"publication"},{"authors":["Estibaliz Gómez-de-Mariscal","Carlos Garcı́a-López-de-Haro","Wei Ouyang","Laurène Donati","Emma Lundberg","Michael Unser","Arrate Muñoz-Barrutia","Daniel Sage"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"7073dd3fe177954bd22b75a47777f088","permalink":"https://aicell.io/publication/gomez-2021-deepimagej/","publishdate":"2023-01-15T23:42:14.908576Z","relpermalink":"/publication/gomez-2021-deepimagej/","section":"publication","summary":"","tags":[],"title":"DeepImageJ: A user-friendly environment to run deep learning models in ImageJ","type":"publication"},{"authors":["Wei Ouyang","Trang Le","Hao Xu","Emma Lundberg"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"7f844a2263a67283cb47f7ff4e1ecbaf","permalink":"https://aicell.io/publication/ouyang-2021-interactive/","publishdate":"2023-01-15T23:42:14.60589Z","relpermalink":"/publication/ouyang-2021-interactive/","section":"publication","summary":"","tags":[],"title":"Interactive biomedical segmentation tool powered by deep learning and ImJoy","type":"publication"},{"authors":["Henry Pinkard","Nico Stuurman","Ivan E Ivanov","Nicholas M Anthony","Wei Ouyang","Bin Li","Bin Yang","Mark A Tsuchida","Bryant Chhun","Grace Zhang"," others"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"9b515321b86300667398af85651ee9cf","permalink":"https://aicell.io/publication/pinkard-2021-pycro/","publishdate":"2023-01-15T23:42:14.755568Z","relpermalink":"/publication/pinkard-2021-pycro/","section":"publication","summary":"","tags":[],"title":"Pycro-Manager: open-source software for customized and reproducible microscope control","type":"publication"},{"authors":["Xian Hao","Jyotsana J Parmar","Benoı̂t Lelandais","Andrey Aristov","Wei Ouyang","Christian Weber","Christophe Zimmer"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ef0c48689bdb89571751f51581bbcfb7","permalink":"https://aicell.io/publication/hao-2021-super/","publishdate":"2023-01-15T23:42:15.059197Z","relpermalink":"/publication/hao-2021-super/","section":"publication","summary":"","tags":[],"title":"Super-resolution visualization and modeling of human chromosomal regions reveals cohesin-dependent loop structures","type":"publication"},{"authors":["admin","吳恩達"],"categories":["Demo","教程"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://aicell.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Christophe Zimmer","Wei Ouyang"],"categories":[],"content":"","date":159624e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"6e3eb0710729b6d1baffc9d2bdf346dc","permalink":"https://aicell.io/publication/zimmer-2020-method/","publishdate":"2023-01-15T23:42:14.303861Z","relpermalink":"/publication/zimmer-2020-method/","section":"publication","summary":"","tags":[],"title":"Method, device, and computer program for improving the reconstruction of dense super-resolution images from diffraction-limited images acquired by single molecule localization microscopy","type":"publication"},{"authors":["Lovisa Stenström","Diana Mahdessian","Christian Gnann","Anthony J Cesnik","Wei Ouyang","Manuel D Leonetti","Mathias Uhlén","Sara Cuylen-Haering","Peter J Thul","Emma Lundberg"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"7cf7ab32fffe636bf7149a03cf62107d","permalink":"https://aicell.io/publication/stenstrom-2020-mapping/","publishdate":"2023-01-15T23:42:14.452132Z","relpermalink":"/publication/stenstrom-2020-mapping/","section":"publication","summary":"","tags":[],"title":"Mapping the nucleolar proteome reveals a spatiotemporal organization related to intrinsic protein disorder","type":"publication"},{"authors":[],"categories":[],"content":"EMBL-EBI Training - Microscopy data analysis\nWei OUYANG\nSciLifeLab | KTH Royal Institute of Technology, Stockholm https://bioimage.io Challenges Training models is difficult Complex hardware/software setup Environmental impact: “Training a single AI model can emit as much carbon as five cars in their lifetimes” Lack of interoperability Hard for non-expert to run 🦒BioImage Model Zoo AI model file standard Hosting pretrained models Test run service User/Developer services 🦒BioImage Model Zoo: Overview 🤔How it works 🔥Demos! Overview: https://bioimage.io/ Find and download models Upload Models Ask for help Meet the BioEngine Deploying the BioEngine BioEngine feature hightlights Many models Many users Many applications Shared GPU resources Both inference and training Local or cloud deployment BioEngine vs Jupyter Notebooks / Colab Scalability!\nCloud \u0026amp; On-premise deployment For multi-user or the public Multi-model serving Improved GPU utilization Instant usage without setup or installation Accessing the BioEngine from Icy Collabration with Carlos García López de Haro and the Icy Team\nAccessing the BioEngine from Icy Collabration with Carlos García López de Haro and the Icy Team\n🔥Hands on tutorial Try the BioEngine\nTutorial 1: Try the bioEngine Go to https://bioimage.io Search for 10.5281/zenodo.5869899 Click the BioEngine icon Click input image to download an sample image Click the select image button, drag and drop the image to elFinder Select the uploaded image Choose the pytorch weights and fill yx in the axes field Click “Submit” Wait for a while and see the result Tutorial 2: Use the BioEnine via JupyterLite Click to start the notebook Reset\nConclusions AI model sharing via BioImage Model Zoo BioEninge for scalable AI model serving Acknowledgements (1) Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg\nBioImage.IO is powered by the 🧠 and ❤️ of:\ndeepImageJ Team EBI Bioimage Archive Team Fiji/ImageJ Team ilastik Team ImJoy Team ZeroCostDL4Mic Team … Follow us on twitter @bioimageio\n🙏Thank You! async function loadNotebook(name, window_id, url, overwrite){ const jupyter = await api.createWindow({src: \u0026#34;https://jupyter.imjoy.io/lab/index.html\u0026#34;, window_id}) const bid = window_id.replace(\u0026#34;window\u0026#34;, \u0026#34;reset\u0026#34;) const button = document.getElementById(bid) if(await jupyter.fileExists(name)){ if(overwrite){ const content = await (await fetch(url)).text() await jupyter.removeFile(name) await jupyter.loadFile(name, content, \u0026#39;application/json\u0026#39;) } await jupyter.openFile(name) } else{ const content = await (await fetch(url)).text() const filePath = await jupyter.loadFile(name, content, \u0026#39;application/json\u0026#39;) await jupyter.openFile(filePath) } button.style.display = \u0026#34;inline-block\u0026#34;; } const PythonPluginCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;PythonPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;native-python\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;flags\u0026#34;: [], \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [], \u0026#34;dependencies\u0026#34;: [] } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;python\u0026#34;\u0026gt; from imjoy import api class ImJoyPlugin(): def setup(self): api.showMessage(\u0026#39;Python plugin initialized\u0026#39;) def add(self, a, b): return a + b api.export(ImJoyPlugin()) \u0026lt;/script\u0026gt; ` const JSPluginCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;JSPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;window\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [], \u0026#34;dependencies\u0026#34;: [], \u0026#34;defaults\u0026#34;: {\u0026#34;w\u0026#34;: 20, \u0026#34;h\u0026#34;: 10} } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;javascript\u0026#34;\u0026gt; window.callPython = async function(){ const pythonPlugin = await api.getPlugin(\u0026#39;PythonPlugin\u0026#39;) const result = await pythonPlugin.add(10, 99) document.getElementById(\u0026#34;result\u0026#34;).innerHTML = \u0026#34;10 + 99 =\u0026#34; + result } class ImJoyPlugin { async setup() { api.log(\u0026#39;initialized\u0026#39;) } async run(ctx) { } } api.export(new ImJoyPlugin()) \u0026lt;/script\u0026gt; \u0026lt;window lang=\u0026#34;html\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;button class=\u0026#34;button\u0026#34; onclick=\u0026#34;callPython()\u0026#34;\u0026gt; Calculate in Python\u0026lt;/button\u0026gt; \u0026lt;h3 id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/h3\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/window\u0026gt; ` window.ZarrPythonCode = ` \u0026lt;config lang=\u0026#34;json\u0026#34;\u0026gt; { \u0026#34;name\u0026#34;: \u0026#34;ZarrPythonPlugin\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;native-python\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;[TODO: describe this plugin with one sentence.]\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;ui\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;cover\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;inputs\u0026#34;: null, \u0026#34;outputs\u0026#34;: null, \u0026#34;flags\u0026#34;: [], \u0026#34;icon\u0026#34;: \u0026#34;extension\u0026#34;, \u0026#34;api_version\u0026#34;: \u0026#34;0.1.8\u0026#34;, \u0026#34;env\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;permissions\u0026#34;: [], \u0026#34;requirements\u0026#34;: [\u0026#34;zarr\u0026#34;, \u0026#34;fsspec\u0026#34;], \u0026#34;dependencies\u0026#34;: [] } \u0026lt;/config\u0026gt; \u0026lt;script lang=\u0026#34;python\u0026#34;\u0026gt; import zarr from imjoy_rpc import api from imjoy_rpc import register_default_codecs from fsspec.implementations.http import HTTPFileSystem register_default_codecs() fs = HTTPFileSystem() http_map = fs.get_mapper(\u0026#34;https://openimaging.github.io/demos/multi-scale-chunked-compressed/build/data/medium.zarr\u0026#34;) z_group = zarr.open(http_map, …","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"e7bd240fed8a7feaae7c2d7ce541db1c","permalink":"https://aicell.io/slides/model-zoo/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/model-zoo/","section":"slides","summary":"BioImage Model Zoo","tags":[],"title":"Slides","type":"slides"},{"authors":["Wei Ouyang","Casper F Winsnes","Martin Hjelmare","Anthony J Cesnik","Lovisa Åkesson","Hao Xu","Devin P Sullivan","Shubin Dai","Jun Lan","Park Jinmo"," others"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"cf2581766a7f08c9c45b5f29663f5153","permalink":"https://aicell.io/publication/ouyang-2019-analysis/","publishdate":"2023-01-15T23:42:14.152962Z","relpermalink":"/publication/ouyang-2019-analysis/","section":"publication","summary":"","tags":[],"title":"Analysis of the human protein atlas image classification competition","type":"publication"},{"authors":["Wei Ouyang","Florian Mueller","Martin Hjelmare","Emma Lundberg","Christophe Zimmer"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"77e672ebccee1635718ca1240fc0c6b6","permalink":"https://aicell.io/publication/ouyang-2019-imjoy/","publishdate":"2023-01-15T23:42:14.004731Z","relpermalink":"/publication/ouyang-2019-imjoy/","section":"publication","summary":"","tags":[],"title":"ImJoy: an open-source computational platform for the deep learning era","type":"publication"},{"authors":["Aubin Samacoits","Racha Chouaib","Adham Safieddine","Abdel-Meneem Traboulsi","Wei Ouyang","Christophe Zimmer","Marion Peter","Edouard Bertrand","Thomas Walter","Florian Mueller"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"867cfe19a1eda290b7b73c5c46ecc4cf","permalink":"https://aicell.io/publication/samacoits-2018-computational/","publishdate":"2023-01-15T23:42:13.687719Z","relpermalink":"/publication/samacoits-2018-computational/","section":"publication","summary":"","tags":[],"title":"A computational framework to study sub-cellular RNA localization","type":"publication"},{"authors":["Wei Ouyang","Andrey Aristov","Mickaël Lelek","Xian Hao","Christophe Zimmer"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"eb1519b72ce2fda12b30cfa5af9f24fd","permalink":"https://aicell.io/publication/ouyang-2018-deep/","publishdate":"2023-01-15T23:42:13.130844Z","relpermalink":"/publication/ouyang-2018-deep/","section":"publication","summary":"","tags":[],"title":"Deep learning massively accelerates super-resolution localization microscopy","type":"publication"},{"authors":["Geng Yang","Mingzhe Jiang","Wei Ouyang","Guangchao Ji","Haibo Xie","Amir M Rahmani","Pasi Liljeberg","Hannu Tenhunen"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"096d9327056fa1ab4c4e0465b5fd4fa3","permalink":"https://aicell.io/publication/yang-2017-iot/","publishdate":"2023-01-15T23:42:13.845957Z","relpermalink":"/publication/yang-2017-iot/","section":"publication","summary":"","tags":[],"title":"IoT-based remote pain monitoring system: From device to cloud platform","type":"publication"},{"authors":["Wei Ouyang","Christophe Zimmer"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"ff22a13aa6bfc12acdb77a65e99fffbb","permalink":"https://aicell.io/publication/ouyang-2017-imaging/","publishdate":"2023-01-15T23:42:13.533989Z","relpermalink":"/publication/ouyang-2017-imaging/","section":"publication","summary":"","tags":[],"title":"The imaging tsunami: computational opportunities and challenges","type":"publication"}]