[{"authors":null,"categories":null,"content":"The AI Cell Lab is a newly formed research group at Science for Life Laboratory and KTH Royal Institute at Technology. The group is led by Wei Ouyang and funded by the Data-Driven Life Science program. The aim of the lab is to build AI systems for data-driven cell and molecular biology.\n⚡ This website is under construction! ","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ea94ad9394f8902e5ea230f6a54da5b5","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"The AI Cell Lab is a newly formed research group at Science for Life Laboratory and KTH Royal Institute at Technology. The group is led by Wei Ouyang and funded by the Data-Driven Life Science program.","tags":null,"title":"AI for Cell Biology Labratory","type":"authors"},{"authors":null,"categories":null,"content":"We are currently hiring PhDs and Postdocs, if you are interested, please contact me at wei.ouyang@scilifelab.se.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1c899dfb626d109eb5250a094bb04a8d","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"We are currently hiring PhDs and Postdocs, if you are interested, please contact me at wei.ouyang@scilifelab.se.","tags":null,"title":"We Are Hiring!","type":"authors"},{"authors":null,"categories":null,"content":"Wei OUYANG is an assistant professor at the applied physics department, KTH Royal Institute of Technology (Stockholm, Sweden). He is one of the Data-Driven Life Science fellow and currently leading a research group focusing on AI and data-driven method development for bioimage analysis and whole-cell modeling.\nDr. Ouyang obtained his PhD in computational image analysis at Institut Pasteur, Paris where he mainly focuses on applying deep learning for super-resolution microscopy. During this period, he developed a deep learning method called ANNA-PALM which massively accelerates super-resolution localization microscopy by 100x. He spent 4 years at Emma Lundberg’s group as a postdoctoral researcher. To address the challenges in the dissemination of AI tools, he developed an open-source computational platform, ImJoy, which makes deep learning tools easier to build and more accessible to the user. He is actively involved in consortiums and community activities for promoting more open, scalable, accessible and reproducible scientific tools. Among them, he is leading the development of the BioImage Model Zoo for sharing AI models in bioimage analysis.\nDr. Ouyang is mainly interested in AI augmented microscopy imaging and data-driven whole-cell modeling.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1ac1287be249f4356037b3f6a33188a9","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Wei OUYANG is an assistant professor at the applied physics department, KTH Royal Institute of Technology (Stockholm, Sweden). He is one of the Data-Driven Life Science fellow and currently leading a research group focusing on AI and data-driven method development for bioimage analysis and whole-cell modeling.","tags":null,"title":"Wei Ouyang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://aicell.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"Deep learning-based approaches are revolutionizing imaging-driven scientific research. However, the accessibility and reproducibility of deep learning-based workflows for imaging scientists remain far from sufficient. Several tools have recently risen to the challenge of democratizing deep learning by providing user-friendly interfaces to analyze new data with pre-trained or fine-tuned models. Still, few of the existing pre-trained models are interoperable between these tools, critically restricting a model’s overall utility and the possibility of validating and reproducing scientific analyses. Here, we present the BioImage Model Zoo (https://bioimage.io): a community-driven, fully open resource where standardized pre-trained models can be shared, explored, tested, and downloaded for further adaptation or direct deployment in multiple end user-facing tools (e.g., ilastik, deepImageJ, QuPath, StarDist, ImJoy, ZeroCostDL4Mic, CSBDeep). To enable everyone to contribute and consume the Zoo resources, we provide a model standard to enable cross-compatibility, a rich list of example models and practical use-cases, developer tools, documentation, and the accompanying infrastructure for model upload, download and testing. Our contribution aims to lay the groundwork to make deep learning methods for microscopy imaging findable, accessible, interoperable, and reusable (FAIR) across software tools and platforms.\nFor more details, see our publication here.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"8bb6bec226676814b1240aaebc889363","permalink":"https://aicell.io/project/model-zoo/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/model-zoo/","section":"project","summary":"AI models for bioimage analysis","tags":["deep learning","AI","models","FAIR","model zoo"],"title":"BioImage Model Zoo","type":"project"},{"authors":null,"categories":null,"content":"Whole-cell modeling enables a holistic and quantitative view of cell biology and allows performing in-silico experimentation which has a great potential in revolutionizing system biology, synthetic biology, medicine and other applications in life science. However, modeling the entire cell is an extremely complex task and is heavily limited by our understanding of the biological systems. As a newly formed research group, we would like to take the grand challenge of building a human cell simulator through recent advances in multi-omics data generation and artificial intelligence. Our aim is to use recent deep learning techniques such as convolutional neural networks, transformers, AlphaFold and diffusion models to analysis existing multi-omics dataset, combining them with massive amount of newly generated live cell, multiplexed images, to model cellular behavior through generative and predictive models.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"3fbb3863a4cdff902fe8e942dc51aaa1","permalink":"https://aicell.io/project/human-cell-simulator/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/human-cell-simulator/","section":"project","summary":"Building AI-powered Data-driven Human Whole-cell Model","tags":["whole-cell modeling","deep learning","AI","computational biology","simulation","generative modeling"],"title":"Human Cell Simulator","type":"project"},{"authors":null,"categories":null,"content":"Deep learning (DL) methods achieve breakthrough performances in analyzing biomedical data across countless tasks, including medical diagnostics, DNA sequence analysis, augmented microscopy and drug design. Combined with increasing data repositories in genomics, imaging and other fields, such successes underlay a growing demand to adapt DL methods to new datasets and questions1. However, the dissemination of DL approaches faces considerable hurdles. Most published DL studies2,3,4,5 require users to retrain models on their own data to obtain the best performance and/or avoid erroneous results. Although trained models are frequently available through web applications or ImageJ plugins, retraining is typically only possible via scripts or command lines, rather than graphical user interfaces (GUIs). In addition, the complexities of setting up the required hardware and software environments often constitute forbidding obstacles6. Furthermore, the large datasets and computational resources typical of current DL successes pose challenges to traditional desktop-oriented software that tightly couple GUI and computation. Cloud services can partly alleviate these difficulties, but raise privacy and confidentiality issues that can be prohibitive for medical data7. Meanwhile, deploying scientific software to mobile platforms can make them accessible to billions of people8, enabling large-scale biomedical research and citizen science. These opportunities and challenges call for new computational frameworks.\nFor more information, read our publication on Nature Methods.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"e30216927b8db55fcce4fc9258591e31","permalink":"https://aicell.io/project/imjoy/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/imjoy/","section":"project","summary":"Supercharging scalability and interactivity","tags":["deep learning","AI","web image analysis","web browser","webassembly"],"title":"ImJoy - Web Data Analysis","type":"project"},{"authors":null,"categories":null,"content":"The aim of the project is to build a smart microscopy imaging farm for massive production of image data. It consists of multiple microscopes and fluidic systems, robotic arms, liquid handling robots and automatic incubators. The farm will be used for performing automated widefield/fluorescence imaging, long-term live cell imaging, tracking, spatial-omics and multiplexing imaging. With the AI-powered control software, data are analyzed in real-time, augmented views are added on the fly. By generating feedback control signals to control the microscope, the software will automatically change field-of-views, illumination power and other experimental conditions in order to optimize the phototoxicity and capture rare events in live cells.\n","date":1672531200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1672531200,"objectID":"b393419260308f5a295bad8d6d547fd0","permalink":"https://aicell.io/project/reef-imaging-farm/","publishdate":"2023-01-01T00:00:00Z","relpermalink":"/project/reef-imaging-farm/","section":"project","summary":"AI-powered Automated Imaging Farm","tags":["deep learning","AI","microscopy","bioimaging","augmented microscopy","robotics","lab automation"],"title":"Reef - Automated Imaging Farm","type":"project"},{"authors":["Wei Ouyang","Richard W Bowman","Haoran Wang","Kaspar E Bumke","Joel T Collins","Ola Spjuth","Jordi Carreras-Puigvert","Benedict Diederich"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"1fa0cd5d35301893aa9866653b413805","permalink":"https://aicell.io/publication/ouyang-2022-open/","publishdate":"2023-01-15T23:42:15.215275Z","relpermalink":"/publication/ouyang-2022-open/","section":"publication","summary":"","tags":[],"title":"An Open-Source Modular Framework for Automated Pipetting and Imaging Applications","type":"publication"},{"authors":["Trang Le","Casper F Winsnes","Ulrika Axelsson","Hao Xu","Jayasankar Mohanakrishnan Kaimal","Diana Mahdessian","Shubin Dai","Ilya S Makarov","Vladislav Ostankovich","Yang Xu"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"b960050c3ff961eaf0707c0f4440f366","permalink":"https://aicell.io/publication/le-2022-analysis/","publishdate":"2023-01-15T23:42:15.851391Z","relpermalink":"/publication/le-2022-analysis/","section":"publication","summary":"","tags":[],"title":"Analysis of the human protein atlas weakly supervised single-cell classification competition","type":"publication"},{"authors":["Wei Ouyang","Fynn Beuttenmueller","Estibaliz Gómez-de-Mariscal","Constantin Pape","Tom Burke","Carlos Garcia-López-de-Haro","Craig Russell","Lucı́a Moya-Sans","Cristina de-la-Torre-Gutiérrez","Deborah Schmidt"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"9d46faf3922a481b1c58ebb4b6b19435","permalink":"https://aicell.io/publication/ouyang-2022-bioimage/","publishdate":"2023-01-15T23:42:15.70073Z","relpermalink":"/publication/ouyang-2022-bioimage/","section":"publication","summary":"","tags":[],"title":"BioImage Model Zoo: A Community-Driven Resource for Accessible Deep Learning in BioImage Analysis","type":"publication"},{"authors":["Arthur Imbert","Wei Ouyang","Adham Safieddine","Emeline Coleno","Christophe Zimmer","Edouard Bertrand","Thomas Walter","Florian Mueller"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ace415f0785196b567324772555d6f9e","permalink":"https://aicell.io/publication/imbert-2022-fish/","publishdate":"2023-01-15T23:42:15.533744Z","relpermalink":"/publication/imbert-2022-fish/","section":"publication","summary":"","tags":[],"title":"FISH-quant v2: a scalable and modular tool for smFISH image analysis","type":"publication"},{"authors":["Wei Ouyang","Jiachuan Bai","Manish Kumar Singh","Christophe Leterrier","Paul Barthelemy","Samuel FH Barnett","Teresa Klein","Markus Sauer","Pakorn Kanchanawong","Nicolas Bourg"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"2aef7662649d0880990ccc8819b98835","permalink":"https://aicell.io/publication/ouyang-2022-shareloc/","publishdate":"2023-01-15T23:42:16.164704Z","relpermalink":"/publication/ouyang-2022-shareloc/","section":"publication","summary":"","tags":[],"title":"ShareLoc-an open platform for sharing localization microscopy data","type":"publication"},{"authors":["Jayasankar Mohanakrishnan Kaimal","Marianna Tampere","Trang H Le","Ulrika Axelsson","Hao Xu","Hanna Axelsson","Anna Backstrom","Francesco Marabita","Elisabeth Moussaud-Lamodiere","Duncan Njenda"," others"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"b5d4bc5c4bd74d1f43f93714ed705d15","permalink":"https://aicell.io/publication/kaimal-2022-subcellular/","publishdate":"2023-01-15T23:42:15.998042Z","relpermalink":"/publication/kaimal-2022-subcellular/","section":"publication","summary":"","tags":[],"title":"Subcellular mapping of the protein landscape of SARS-CoV-2 infected cells for target-centric drug repurposing","type":"publication"},{"authors":["Matthew R King","Andrew Z Lin","Kiersten M Ruff","Mina Farag","Wei Ouyang","Michael D Vahey","Emma Lundberg","Rohit V Pappu"],"categories":[],"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826136,"objectID":"a45bc65019334a279fd4f113e312532b","permalink":"https://aicell.io/publication/king-2022-uncovering/","publishdate":"2023-01-15T23:42:16.315261Z","relpermalink":"/publication/king-2022-uncovering/","section":"publication","summary":"","tags":[],"title":"Uncovering molecular grammars of intrinsically disordered regions that organize nucleolar fibrillar centers","type":"publication"},{"authors":[],"categories":[],"content":"ImJoy: Supercharging Interactivity and Scalability for BioImage Analysis Wei Ouyang\nKTH | SciLifeLab, Stockholm\nChallenges in AI for bioimaging Usability: User friendly GUI Flexibility: Flexible for different data types Interactivity: Respond to GUI on laptop/mobile Scalability: Remote storage and compute resources Privacy: Edge computing Progressive Web App Rich and interactive UI libraries Computation in the browser (+cloud) Offline support ImJoy https://imjoy.io Data science tools in the browser\n--- # Key concepts * Sandboxed plugins connected via Remote Procedure calls * Workflow composition via asynchronous programming * Open Integration with existing software/website 👐Open Integration with Web Apps Customize annotation workflow with Kaibu\n// load the web app via its URL viewer = await api.createWindow({src: \u0026#34;https://kaibu.org/#/app\u0026#34;}) // call api functions directly via RPC // add an image layer await viewer.view_image(\u0026#34;https://images.proteinatlas.org/61448/1319_C10_2_blue_red_green.jpg\u0026#34;) // add an annotation layer await viewer.add_shapes([], {name:\u0026#34;annotation\u0026#34;}) 🔥Demo: Visualization with Vizarr Made by Trevor Manz et. al.\n🚀A rapid growing list of plugins ImageJ.JS File Manager Vizarr for visualizing zarr images ITK/VTK Viewer for 3D visualizing ImJoy Slides ImJoy Chart Editor Works with Jupyter/Binder and Colab Conclusions ImJoy is built for scalability and interactivity ImJoy plugins are sandbox services connected via RPC Acknowledgements Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg\n🙏Thank You! ","date":1612483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612483200,"objectID":"18f800b55b15ac08a8ea3d27298bcf1f","permalink":"https://aicell.io/slides/imjoy/","publishdate":"2021-02-05T00:00:00Z","relpermalink":"/slides/imjoy/","section":"slides","summary":"ImJoy","tags":[],"title":"Slides","type":"slides"},{"authors":["Yue Qin","Edward L Huttlin","Casper F Winsnes","Maya L Gosztyla","Ludivine Wacheul","Marcus R Kelly","Steven M Blue","Fan Zheng","Michael Chen","Leah V Schaffer"," others"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ab242eb12325e50c3f34338d392fbd7b","permalink":"https://aicell.io/publication/qin-2021-multi/","publishdate":"2023-01-15T23:42:15.364803Z","relpermalink":"/publication/qin-2021-multi/","section":"publication","summary":"","tags":[],"title":"A multi-scale map of cell structure fusing protein images and interactions","type":"publication"},{"authors":["Estibaliz Gómez-de-Mariscal","Carlos Garcı́a-López-de-Haro","Wei Ouyang","Laurène Donati","Emma Lundberg","Michael Unser","Arrate Muñoz-Barrutia","Daniel Sage"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"7073dd3fe177954bd22b75a47777f088","permalink":"https://aicell.io/publication/gomez-2021-deepimagej/","publishdate":"2023-01-15T23:42:14.908576Z","relpermalink":"/publication/gomez-2021-deepimagej/","section":"publication","summary":"","tags":[],"title":"DeepImageJ: A user-friendly environment to run deep learning models in ImageJ","type":"publication"},{"authors":["Wei Ouyang","Trang Le","Hao Xu","Emma Lundberg"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"7f844a2263a67283cb47f7ff4e1ecbaf","permalink":"https://aicell.io/publication/ouyang-2021-interactive/","publishdate":"2023-01-15T23:42:14.60589Z","relpermalink":"/publication/ouyang-2021-interactive/","section":"publication","summary":"","tags":[],"title":"Interactive biomedical segmentation tool powered by deep learning and ImJoy","type":"publication"},{"authors":["Henry Pinkard","Nico Stuurman","Ivan E Ivanov","Nicholas M Anthony","Wei Ouyang","Bin Li","Bin Yang","Mark A Tsuchida","Bryant Chhun","Grace Zhang"," others"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"9b515321b86300667398af85651ee9cf","permalink":"https://aicell.io/publication/pinkard-2021-pycro/","publishdate":"2023-01-15T23:42:14.755568Z","relpermalink":"/publication/pinkard-2021-pycro/","section":"publication","summary":"","tags":[],"title":"Pycro-Manager: open-source software for customized and reproducible microscope control","type":"publication"},{"authors":["Xian Hao","Jyotsana J Parmar","Benoı̂t Lelandais","Andrey Aristov","Wei Ouyang","Christian Weber","Christophe Zimmer"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826135,"objectID":"ef0c48689bdb89571751f51581bbcfb7","permalink":"https://aicell.io/publication/hao-2021-super/","publishdate":"2023-01-15T23:42:15.059197Z","relpermalink":"/publication/hao-2021-super/","section":"publication","summary":"","tags":[],"title":"Super-resolution visualization and modeling of human chromosomal regions reveals cohesin-dependent loop structures","type":"publication"},{"authors":["admin","吳恩達"],"categories":["Demo","教程"],"content":"Overview The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It’s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more The template is mobile first with a responsive design to ensure that your site looks stunning on every device. Get Started 👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Tutorial and Release Notes Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy’s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem Hugo Academic CLI: Automatically import publications from BibTeX Inspiration Check out the latest demo of what you’ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files. Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://aicell.io/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Christophe Zimmer","Wei Ouyang"],"categories":[],"content":"","date":159624e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"6e3eb0710729b6d1baffc9d2bdf346dc","permalink":"https://aicell.io/publication/zimmer-2020-method/","publishdate":"2023-01-15T23:42:14.303861Z","relpermalink":"/publication/zimmer-2020-method/","section":"publication","summary":"","tags":[],"title":"Method, device, and computer program for improving the reconstruction of dense super-resolution images from diffraction-limited images acquired by single molecule localization microscopy","type":"publication"},{"authors":["Lovisa Stenström","Diana Mahdessian","Christian Gnann","Anthony J Cesnik","Wei Ouyang","Manuel D Leonetti","Mathias Uhlén","Sara Cuylen-Haering","Peter J Thul","Emma Lundberg"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"7cf7ab32fffe636bf7149a03cf62107d","permalink":"https://aicell.io/publication/stenstrom-2020-mapping/","publishdate":"2023-01-15T23:42:14.452132Z","relpermalink":"/publication/stenstrom-2020-mapping/","section":"publication","summary":"","tags":[],"title":"Mapping the nucleolar proteome reveals a spatiotemporal organization related to intrinsic protein disorder","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\nFeatures Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides Controls Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;) Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\nFragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne Two Three A fragment can accept two optional parameters:\nclass: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\nOnly the speaker can read these notes Press S key to view Themes black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}} Custom CSS Example Let’s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; } Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://aicell.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":[],"categories":[],"content":" Wei OUYANG\nSciLifeLab | KTH Royal Institute of Technology, Stockholm\nhttps://bioimage.io Challenges Training models is difficult Complex hardware/software setup Environmental impact: “Training a single AI model can emit as much carbon as five cars in their lifetimes” Lack of interoperability Hard for non-expert to run 🦒BioImage Model Zoo AI model file standard Hosting pretrained models Test run service User/Developer services 🦒BioImage Model Zoo: Overview 🤔How it works 🔥Demos! Overview: https://bioimage.io/ Find and download models Upload Models Ask for help Meet the BioEngine Deploying the BioEngine BioEngine feature hightlights Many models Many users Many applications Shared GPU resources Both inference and training Local or cloud deployment BioEngine vs Jupyter Notebooks / Colab Scalability!\nCloud \u0026amp; On-premise deployment For multi-user or the public Multi-model serving Improved GPU utilization Instant usage without setup or installation Accessing the BioEngine from Icy Collabration with Carlos García López de Haro and the Icy Team\nAccessing the BioEngine from Icy Collabration with Carlos García López de Haro and the Icy Team\nConclusions AI model sharing via BioImage Model Zoo BioEninge for scalable AI model serving Acknowledgements (1) Work carried out at Cell Profiling group @ SciLifeLab headed by Emma Lundberg\nBioImage.IO is powered by the 🧠 and ❤️ of:\ndeepImageJ Team EBI Bioimage Archive Team Fiji/ImageJ Team ilastik Team ImJoy Team ZeroCostDL4Mic Team … Follow us on twitter @bioimageio\n🙏Thank You! ","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"e7bd240fed8a7feaae7c2d7ce541db1c","permalink":"https://aicell.io/slides/model-zoo/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/model-zoo/","section":"slides","summary":"BioImage Model Zoo","tags":[],"title":"Slides","type":"slides"},{"authors":["Wei Ouyang","Casper F Winsnes","Martin Hjelmare","Anthony J Cesnik","Lovisa Åkesson","Hao Xu","Devin P Sullivan","Shubin Dai","Jun Lan","Park Jinmo"," others"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"cf2581766a7f08c9c45b5f29663f5153","permalink":"https://aicell.io/publication/ouyang-2019-analysis/","publishdate":"2023-01-15T23:42:14.152962Z","relpermalink":"/publication/ouyang-2019-analysis/","section":"publication","summary":"","tags":[],"title":"Analysis of the human protein atlas image classification competition","type":"publication"},{"authors":["Wei Ouyang","Florian Mueller","Martin Hjelmare","Emma Lundberg","Christophe Zimmer"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826134,"objectID":"77e672ebccee1635718ca1240fc0c6b6","permalink":"https://aicell.io/publication/ouyang-2019-imjoy/","publishdate":"2023-01-15T23:42:14.004731Z","relpermalink":"/publication/ouyang-2019-imjoy/","section":"publication","summary":"","tags":[],"title":"ImJoy: an open-source computational platform for the deep learning era","type":"publication"},{"authors":["Aubin Samacoits","Racha Chouaib","Adham Safieddine","Abdel-Meneem Traboulsi","Wei Ouyang","Christophe Zimmer","Marion Peter","Edouard Bertrand","Thomas Walter","Florian Mueller"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"867cfe19a1eda290b7b73c5c46ecc4cf","permalink":"https://aicell.io/publication/samacoits-2018-computational/","publishdate":"2023-01-15T23:42:13.687719Z","relpermalink":"/publication/samacoits-2018-computational/","section":"publication","summary":"","tags":[],"title":"A computational framework to study sub-cellular RNA localization","type":"publication"},{"authors":["Wei Ouyang","Andrey Aristov","Mickaël Lelek","Xian Hao","Christophe Zimmer"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"eb1519b72ce2fda12b30cfa5af9f24fd","permalink":"https://aicell.io/publication/ouyang-2018-deep/","publishdate":"2023-01-15T23:42:13.130844Z","relpermalink":"/publication/ouyang-2018-deep/","section":"publication","summary":"","tags":[],"title":"Deep learning massively accelerates super-resolution localization microscopy","type":"publication"},{"authors":["Geng Yang","Mingzhe Jiang","Wei Ouyang","Guangchao Ji","Haibo Xie","Amir M Rahmani","Pasi Liljeberg","Hannu Tenhunen"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"096d9327056fa1ab4c4e0465b5fd4fa3","permalink":"https://aicell.io/publication/yang-2017-iot/","publishdate":"2023-01-15T23:42:13.845957Z","relpermalink":"/publication/yang-2017-iot/","section":"publication","summary":"","tags":[],"title":"IoT-based remote pain monitoring system: From device to cloud platform","type":"publication"},{"authors":["Wei Ouyang","Christophe Zimmer"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673826133,"objectID":"ff22a13aa6bfc12acdb77a65e99fffbb","permalink":"https://aicell.io/publication/ouyang-2017-imaging/","publishdate":"2023-01-15T23:42:13.533989Z","relpermalink":"/publication/ouyang-2017-imaging/","section":"publication","summary":"","tags":[],"title":"The imaging tsunami: computational opportunities and challenges","type":"publication"}]